{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xyE9aoVFTMHD",
        "NDCTSjhgT_Tu",
        "qhFw2eu8UL2n",
        "Co1JeykiQqmT",
        "1emnwJoh70lS",
        "4GMvfo4rl9yv",
        "O2u6qMQhzfdK",
        "PYbxHBVXj0AN",
        "hA6z_mhF3hGy",
        "9SBBVBHD8XxH",
        "YRj2kQHf89pB",
        "SDjRuyEs9-tb",
        "OvwP42cYFYj3",
        "IM4ocUGAtCU_",
        "oXXyiL5iu8zy",
        "vD9pxqEZU0zp"
      ],
      "toc_visible": true,
      "mount_file_id": "1RVrCAQGjg8_rEMiTzwpovgosBDN6NPCv",
      "authorship_tag": "ABX9TyN4zJ5V8VYHBgMukS4tXDsR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauricionoronha/classificador_generico_simplificado/blob/main/classificador_generico_simplificado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 1 : Pré-processamento dos dados:</font>\n",
        "\n",
        "* É o processo de limpar, transformar e preparar os dados brutos antes de serem alimentados para um modelo de aprendizado de máquina. \n",
        "\n",
        "* É uma etapa crucial em qualquer projeto de machine learning, pois a qualidade dos dados usados para treinar um modelo tem um grande impacto no desempenho e na precisão do modelo.\n",
        "\n",
        ">Considerada a etapa mais demorada e trabalhosa, mas neste projeto será otimizado em 10 passos. Basta preencher as informações necessárias e rodar a célula.\n"
      ],
      "metadata": {
        "id": "9egPmqojeq0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 1/10 - Carregando a base de dados:</font>"
      ],
      "metadata": {
        "id": "xyE9aoVFTMHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yvd3YeQPXbRJ"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print('\u001b[1;32mCarregando dados...')\n",
        "# Criação dos campos de preenchimento usando #@param\n",
        "#@markdown > ### Insira o endereço do arquivo abaixo e escolha o tipo correto de arquivo que deseja importar:\n",
        "endereco = \"/content/drive/MyDrive/MACHINE_LEARNNING/telecom_users.xlsx\" #@param {type:\"string\"}\n",
        "tipo_arquivo = \"excel\" #@param [\"csv\", \"excel\"]\n",
        "separador = \";\" #@param [\",\", \";\"]\n",
        "\n",
        "if tipo_arquivo == \"csv\":\n",
        "    dados = pd.read_csv( endereco, sep = separador)\n",
        "else:\n",
        "    dados = pd.read_excel(endereco)\n",
        "\n",
        "print('\u001b[1;32mPronto, verifique as 5 primeiras linhas do dataframe:')\n",
        "dados.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 2/10 - Analisando atributos ( variáveis )</font>"
      ],
      "metadata": {
        "id": "BaOitZZTTmsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown  ### Análise quantitativa em % e visualização gráfica por meio de um histograma.\n",
        "#@markdown \n",
        "#@markdown > Informe o nome do atributo que deseja analisar:\n",
        "import plotly.express as px\n",
        "Nome_Atributo = \"Churn\" #@param {type:\"string\"}\n",
        "\n",
        "print('\u001b[1;32mCriando gráfico...')\n",
        "print(display(dados[Nome_Atributo].value_counts(normalize=True).map(\"{:.1%}\".format)));\n",
        "\n",
        "hist1 =  px.histogram (dados,  x = Nome_Atributo, nbins=60) \n",
        "hist1.update_layout(width=800,height=500,title_text='Distribuição {}'.format(Nome_Atributo)) \n",
        "hist1.show()\n",
        "\n",
        "dados2 = dados.copy()\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "id": "xD2rHyH9r68a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 3/10 - Verificando e corrigindo valores nulos ( NAN )</font>"
      ],
      "metadata": {
        "id": "NDCTSjhgT_Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "print('\u001b[1;32mVerificando dados...')\n",
        "#@markdown > ### Rode essa célula para identificar valores nulos\n",
        "print('\\033[0m' + str(dados2.isnull().sum()))\n",
        "print('\\033[1;32mPronto')"
      ],
      "metadata": {
        "id": "u4HyanG9xU3q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Se encontado valores nulos, como proceder?\n",
        "\n",
        "#@markdown 1 - Excluir Dados Nulos\n",
        "\n",
        "#@markdown 2 - Substituir Dados Nulos Pela Média\n",
        "\n",
        "Escolha = 1 #@param [\"1\", \"2\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown > ###  Informe o nome do Atributo com dados nulos:\n",
        "\n",
        "Nome_Atrib_Dados_Nulos = \"Churn\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if Escolha == 1:\n",
        "    dados2.dropna(inplace=True)\n",
        "else:\n",
        "    dados2[Nome_Atrib_Dados_Nulos].fillna(dados2[Nome_Atrib_Dados_Nulos].mean(), inplace=True)\n",
        "\n",
        "print('\u001b[1;32mDados corrigidos!')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zfn3RNBhx8GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'>  4/10 - Analisando os tipos de atributos</font>"
      ],
      "metadata": {
        "id": "qhFw2eu8UL2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown  ### Verifique os tipos de atributos, que podem ser:\n",
        "#@markdown * object: strings\n",
        "#@markdown * int64: inteiros\n",
        "#@markdown * float64: reais\n",
        "#@markdown * complex: complexos\n",
        "print('\u001b[1;32mAnalisando dados...')\n",
        "print('\\033[0m' + str(dados2.dtypes))\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5P83WgrUTbhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Será necessário alterar o tipo de um atributo especifico?\n",
        "\n",
        "#@markdown * Desconsidere se não for necessário corrigir o tipo do atributo\n",
        "print('\u001b[1;32mCorrigindo dados...')\n",
        "#@markdown > Se for necessário fazer a correção, informe o nome do atributo:\n",
        "Nome_Atributo = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Escolha agora, entre as opções abaixo, para qual tipo deseja alterar:\n",
        "Tipo_Atributo = \"float64\" #@param [\"object\", \"int64\", \"float64\"]\n",
        "\n",
        "if Tipo_Atributo == \"object\":\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].astype(str)\n",
        "elif Tipo_Atributo == \"int64\":\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].apply(np.int64)\n",
        "else:\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].apply(np.float64)\n",
        "\n",
        "print(dados2[Nome_Atributo].dtype)\n",
        "\n",
        "#@markdown * OBS.: Só é possivel converter uma STRING (object) em INT ou FLOAT quando essa string é composta apenas por números, logo não é possivel converter palavras em int ou float\n",
        "print('\u001b[1;32mPronto')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TgB94TvCU9ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 5/10 - Excluindo atributos desnecessários</font>"
      ],
      "metadata": {
        "id": "-eqwHOX7UYNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Informe o nome do atributo que deseja retirar do dataframe:\n",
        "Nome_Atributo = \"ValorBackupOnline\" #@param {type:\"string\"}\n",
        "dados2 = dados2.drop(Nome_Atributo, axis=1)\n",
        "print('\\033[1;32mAtributo excluído!')\n",
        "print('\\033[1;32mSegue amostra do dataframe atualizado:')\n",
        "dados2.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z-GPY4L3vgqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 6/10 - Relação quantitativa entre todos os atributos e um atributo chave:</font>"
      ],
      "metadata": {
        "id": "PfgY51n4UqNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### Veja através de histograma como o atributo chave é distribuído nos demais atributos do dataframe.\n",
        "print('\u001b[1;32mCriando gráficos...')\n",
        "#@markdown > Informe o nome do atributo chave: \n",
        "import plotly.express as px\n",
        "\n",
        "Atributo_Chave = \"\" #@param{type: 'string'}\n",
        "\n",
        "for coluna in dados2:      \n",
        "        fig = px.histogram(dados2, x=coluna,nbins=60, color=Atributo_Chave)\n",
        "        fig.show()\n",
        "\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PBSyUs3cv394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 7/10 - Análise Estatística Descritiva</font>"
      ],
      "metadata": {
        "id": "qynKFN-CUzLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "\n",
        "#@markdown > ### Tenha acesso aos seguintes perâmetros :\n",
        "\n",
        "#@markdown * count: número de valores não nulos na coluna\n",
        "#@markdown * mean: média dos valores na coluna\n",
        "#@markdown * std: desvio padrão dos valores na coluna\n",
        "#@markdown * 25%: primeiro quartil (valor abaixo do qual estão 25% dos valores)\n",
        "#@markdown * 50%: segundo quartil, que é equivalente à mediana (valor abaixo do qual estão 50% dos valores)\n",
        "#@markdown * 75%: terceiro quartil (valor abaixo do qual estão 75% dos valores)\n",
        "#@markdown * max: valor máximo na coluna\n",
        "print('\u001b[1;32mAnalisando dados...')\n",
        "dados2.describe()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8RvSVg1zl3bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 8/10 - Verificando correlação entre variáveis</font>"
      ],
      "metadata": {
        "id": "NqrTozV7VAQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Rode a célula para verificar em um quadro com gráficos de dispersão se existe alguma correlação entre variáveis\n",
        "print('\u001b[1;32mProcessando dados...')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.pairplot(dados2);\n",
        "\n",
        "print('\u001b[1;32mCriando gráficos...')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h-mKI5CzSVfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 9/10 - Verificando Outliers</font>"
      ],
      "metadata": {
        "id": "rwl8NLRgVIi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Informe o nome do atributo para criar um gráfico Boxplot e identificar possíveis outliers ( discrepâncias ):\n",
        "print('\u001b[1;32mCriando gráfico...')\n",
        "Nome_Atributo = \"ValorMensal\" #@param {type:\"string\"}\n",
        "\n",
        "import plotly.express as px\n",
        "px.box ( dados2, y = Nome_Atributo)\n",
        "\n",
        "#@markdown * Apropriado para atributos categóricos ordinais ( que tenham valores numéricos )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HDeB4Kl2BL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Corrigindo outliers\n",
        "#@markdown ---\n",
        "#@markdown > ###  Informe o atributo para correção:\n",
        "Nome_Atributo = \"ValorTelefone\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown >###  Informe como tratar outliers:\n",
        "#@markdown * 1 - Exclua valores discrepantes baseados um uma condição\n",
        "#@markdown * 2 - Substitua valores discrepantes pela média baseado em uma condição\n",
        "#@markdown * 3 - Substitua valores discrepantes por um valor específico baseado em uma condição\n",
        "Tipo_correcao = \"2\" #@param [\"1\", \"2\", \"3\"]\n",
        "\n",
        "#@markdown > ###  Informe agora qual a condição:\n",
        "#@markdown Corrija todos os valores que sejam:\n",
        "Tipo_condicao = \"maior_que\" #@param [\"igual_a\", \"maior_que\", \"menor_que\", \"diferente_de\"]\n",
        "Valor = 0 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown > Se escolheu a opção 3 para substituir os valores discrepantes por um valor específico, informe o valor para qual deseja substituir:\n",
        "Valor_substituição = 0 #@param {type:\"number\"}\n",
        "\n",
        "if Tipo_correcao == 1:\n",
        "    # excluir os dados de um atributo baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] == Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] > Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] < Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] != Valor].index, inplace = True)\n",
        "elif Tipo_correcao == 2:\n",
        "    # substituir os dados de um atributo pela média baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2.loc[dados2[Nome_Atributo] == Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] > Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] < Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2.loc[dados2[Nome_Atributo] != Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "else:\n",
        "    # substituir os dados de um atributo por um valor específico baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2.loc[dados2[Nome_Atributo] == Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] > Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] < Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2.loc[dados2[Nome_Atributo] != Valor, Nome_Atributo] = Valor_substituição\n",
        "\n",
        "print('\u001b[1;32mDados corrigidos!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ovR0rA4CF6Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 10/10 Salvando ou Carregando a base de dados pré-processada</font>"
      ],
      "metadata": {
        "id": "cY96PyqMpRGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### Opcionalmente é possivel salvar o dataframe tratado como um arquivo csv para consultas posteriores e também é possível carregar um dataframe salvo \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#@markdown >  Se deseja salvar o dataframe tratado, marque a caixa abaixo e informe o nome do arquivo:\n",
        "Salvar = False #@param {type:\"boolean\"}\n",
        "Nome_arquivo = \"churn_TRATADO\" #@param {type:\"string\"}\n",
        "Nome_arquivo_csv = Nome_arquivo + \".csv\"\n",
        "\n",
        "if Salvar:\n",
        "  dados2.to_csv(Nome_arquivo_csv,sep = \",\", encoding = \"utf-8\",  index = False)\n",
        "  print('\u001b[1;32mDados Salvos!')\n",
        "\n",
        "#@markdown >  Se deseja carregar um dataframe tratado, marque a caixa abaixo e informe o endereço do arquivo e o separador:\n",
        "Carregar = True #@param {type:\"boolean\"}\n",
        "endereco = \"/content/drive/MyDrive/MACHINE_LEARNNING/churn_TRATADO.csv\" #@param {type:\"string\"}\n",
        "separador = \",\" #@param [\",\", \";\"]\n",
        "\n",
        "if Carregar:\n",
        "    dados2 = pd.read_csv(endereco, sep = separador, encoding = \"utf-8\")\n",
        "    print('\u001b[1;32mPronto, Dataframe carregado!'),\n",
        "    print('\\033[0m' + str(\"\"))\n",
        "    print('\\033[0m' + str(dados2.info()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yZyQie9cqDjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'>  ETAPA 2: Otimização dos dados para a criação do modelo</font>"
      ],
      "metadata": {
        "id": "Vxl0YBa3fRBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Transformando variáveis categóricas NOMINAIS em variáveis categóricas ORDINAIS </font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * ### É extremamente importante assegurar que não existam dados nominais (string) no dataframe, pois os modelos de machine learning usados entendem apenas dados numéricos (int ou float)\n",
        "\n",
        "#@markdown * Essa tranformação ocorre do seguinte modo:\n",
        "\n",
        "#@markdown * Considere um atributo Sexo com 2 opções: Masculino e Feminino. \n",
        "\n",
        "#@markdown * Realizando a transformação, os dados nominais \"Masculino\" e \"Feminino\" serão substituídos por dados ordinais 0 e 1. \n",
        "\n",
        "#@markdown  > ###  >>> Rode a célula para realizar os ajustes <<<\n",
        "\n",
        "# Armazenando os indices das variaveis nominais para uso posterior ( onehotencoder )\n",
        "indice_nominal = [dados2.columns.get_loc(col) for col in dados2.select_dtypes(include=[object]).columns]\n",
        "\n",
        "# Importação da biblioteca para transformar as variáveis\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Criando uma lista com todos os atributos nominais\n",
        "nominais = [i for i, dtype in enumerate(dados2.dtypes) if dtype == object]\n",
        "\n",
        "# Usando LabelEncoder para transformar todos atributos nominais lista em ordinais \n",
        "for i in nominais:\n",
        "    dados2.iloc[:, i] = LabelEncoder().fit_transform(dados2.iloc[:, i])\n",
        "\n",
        "print('\u001b[1;32mDados alterados!')\n",
        "print('\\033[1;32mSegue amostra do dataframe atualizado:')\n",
        "dados2.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Uihn4CWJiJrS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "5311e7f1-67ef-4984-8ebd-a27ac7904701"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDados alterados!\n",
            "\u001b[1;32mSegue amostra do dataframe atualizado:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Genero  Dependentes  MesesComoCliente  ServicoTelefone  ValorTelefone  \\\n",
              "0       0            1                 9                1           54.9   \n",
              "1       1            0                 9                1           54.9   \n",
              "2       1            0                 4                1           54.9   \n",
              "3       1            0                13                1           54.9   \n",
              "4       0            0                 3                1           54.9   \n",
              "\n",
              "   MultiplasLinhas  ServicoInternet  ValorInternet  ServicoSegurancaOnline  \\\n",
              "0                0                0           94.9                       0   \n",
              "1                2                0           94.9                       0   \n",
              "2                0                1          129.9                       0   \n",
              "3                0                1          129.9                       0   \n",
              "4                0                1          129.9                       0   \n",
              "\n",
              "   ServicoBackupOnline  ProtecaoEquipamento  ServicoSuporteTecnico  \\\n",
              "0                    2                    0                      2   \n",
              "1                    0                    0                      0   \n",
              "2                    0                    2                      0   \n",
              "3                    2                    2                      0   \n",
              "4                    0                    0                      2   \n",
              "\n",
              "   ServicoStreamingTV  ServicoFilmes  TipoContrato  FaturaDigital  \\\n",
              "0                   2              0             1              1   \n",
              "1                   0              2             2              0   \n",
              "2                   0              0             2              1   \n",
              "3                   2              2             2              1   \n",
              "4                   2              0             2              1   \n",
              "\n",
              "   FormaPagamento  ValorMensal  Churn  \n",
              "0               1        199.6      0  \n",
              "1               1        169.7      0  \n",
              "2               0        184.8      1  \n",
              "3               0        254.5      1  \n",
              "4               1        224.7      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd6d8c08-ab79-406f-95dd-37f1e322618c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Genero</th>\n",
              "      <th>Dependentes</th>\n",
              "      <th>MesesComoCliente</th>\n",
              "      <th>ServicoTelefone</th>\n",
              "      <th>ValorTelefone</th>\n",
              "      <th>MultiplasLinhas</th>\n",
              "      <th>ServicoInternet</th>\n",
              "      <th>ValorInternet</th>\n",
              "      <th>ServicoSegurancaOnline</th>\n",
              "      <th>ServicoBackupOnline</th>\n",
              "      <th>ProtecaoEquipamento</th>\n",
              "      <th>ServicoSuporteTecnico</th>\n",
              "      <th>ServicoStreamingTV</th>\n",
              "      <th>ServicoFilmes</th>\n",
              "      <th>TipoContrato</th>\n",
              "      <th>FaturaDigital</th>\n",
              "      <th>FormaPagamento</th>\n",
              "      <th>ValorMensal</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>54.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94.9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>199.6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>54.9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>94.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>169.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>54.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>129.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>184.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>54.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>129.9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>254.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>54.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>129.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>224.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd6d8c08-ab79-406f-95dd-37f1e322618c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd6d8c08-ab79-406f-95dd-37f1e322618c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd6d8c08-ab79-406f-95dd-37f1e322618c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Divisão de Previsores e Alvo </font>\n",
        "#@markdown ---\n",
        "#@markdown * Atributos Previsores - (também conhecidos como \"features\" ou \"variáveis independentes\") são as características ou variáveis de entrada que são utilizadas para prever o valor de uma variável de saída. Em outras palavras, os atributos previsores são as informações que alimentam um modelo de machine learning, com o objetivo de produzir uma previsão ou classificação.\n",
        "#@markdown * Atributo Alvo (também conhecido como \"variável dependente\" ou \"rótulo\") é a variável de saída que o modelo de machine learning está tentando prever ou classificar com base nos atributos previsores.\n",
        "\n",
        "#@markdown > ### Informe o Atributo Alvo do dataframe:\n",
        "Nome_Atributo = \"Churn\" #@param {type:\"string\"}\n",
        "# o complemento .values retorna uma matriz com os dados do dataframe\n",
        "# Divisão previsores e alvo\n",
        "previsores = dados2.drop(Nome_Atributo, axis=1).values\n",
        "alvo = dados2[[Nome_Atributo]].values\n",
        "\n",
        "# Excluindo o atributo Alvo da lista de indice_nominal\n",
        "indice_alvo = dados2.columns.get_loc(Nome_Atributo)\n",
        "indice_nominal.remove(indice_alvo)\n",
        "print('\u001b[1;32mPrevisores e Alvo criados!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T_UzrRVdpyqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fea524-925c-4885-ebfb-84bb5e6a9cf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mPrevisores e Alvo criados!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Escalonamento de variáveis </font>\n",
        "#@markdown ---\n",
        "#@markdown * O objetivo do escalonamento de variáveis é normalizar as variáveis para que elas tenham a mesma escala e variem em uma faixa semelhante.\n",
        "\n",
        "#@markdown * Isso é necessário porque muitos algoritmos de Machine Learning são sensíveis à escala das variáveis. Se as variáveis tiverem escalas muito diferentes, isso pode levar a problemas como o algoritmo atribuir maior importância a variáveis com escalas maiores e menor importância a variáveis com escalas menores. Além disso, pode afetar a convergência dos algoritmos.\n",
        "\n",
        "#@markdown  > ###  >>> Rode a célula para realizar os ajustes <<<\n",
        "\n",
        "# Importanto as bibliotecas necessárias:\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "previsores_one = ColumnTransformer(transformers = [(\"OneHot\", OneHotEncoder(), indice_nominal)],\n",
        "                                       remainder = \"passthrough\").fit_transform(previsores)\n",
        "\n",
        "previsores_esc = StandardScaler().fit_transform(previsores_one)                                       \n",
        "print('\u001b[1;32mEscalonamento efetuado!')\n",
        "print('\u001b[1;32mSegue os dados escalonados:')\n",
        "previsores_esc\n"
      ],
      "metadata": {
        "id": "ocSXBXxBzmBl",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ffca22-6013-4246-a523-e2404878e8d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mEscalonamento efetuado!\n",
            "\u001b[1;32mSegue os dados escalonados:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.01923578, -1.01923578, -1.5306916 , ..., -0.65455138,\n",
              "        -0.31864502, -0.39402955],\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.65455138,\n",
              "        -0.31864502, -0.59847607],\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.65455138,\n",
              "         0.01691246, -0.49522716],\n",
              "       ...,\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.80079527,\n",
              "         0.20865958, -0.29078064],\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.80079527,\n",
              "        -0.31864502, -0.7352296 ],\n",
              "       [-0.98112726,  0.98112726, -1.5306916 , ..., -0.80079527,\n",
              "        -0.31864502, -0.59915984]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  ## <font color='#FFA500'> Separando base de treino e teste </font>\n",
        "#@markdown ---\n",
        "#@markdown * Informe o tamanho em porcentagem dos dados de teste. O restante será separado automaticamente para dos dados de treino. \n",
        "\n",
        "1#@markdown > O tamanho padrão de dados de teste é de 30% mas você pode escolher outros tamanhos conforme a necessidade: \n",
        "Tamanho_Base_Teste = \"30% - PADRAO\" #@param [\"10%\", \"15%\", \"20%\", \"25%\", \"30% - PADRAO\", \"35%\", \"40%\", \"45%\", \"50%\"]\n",
        "if Tamanho_Base_Teste == \"20%\":\n",
        "    Tamanho_Teste = 0.2\n",
        "elif Tamanho_Base_Teste == \"25%\":\n",
        "    Tamanho_Teste = 0.25\n",
        "elif Tamanho_Base_Teste == \"30% - PADRAO\":\n",
        "    Tamanho_Teste = 0.3\n",
        "elif Tamanho_Base_Teste == \"35%\":\n",
        "    Tamanho_Teste = 0.35\n",
        "elif Tamanho_Base_Teste == \"40%\":\n",
        "    Tamanho_Teste = 0.4\n",
        "elif Tamanho_Base_Teste == \"45%\":\n",
        "    Tamanho_Teste = 0.45\n",
        "elif Tamanho_Base_Teste == \"50%\":\n",
        "    Tamanho_Teste = 0.5\n",
        "else:\n",
        "    print(\"Valor inválido para Tamanho_Base_Teste\")\n",
        "\n",
        "# Importação de biblioteca \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divisão de dados de treino e teste:\n",
        "x_treino,x_teste,y_treino,y_teste = train_test_split(previsores_esc, alvo, test_size=Tamanho_Teste, random_state=0)\n",
        "\n",
        "print('\\033[1;32mDivisão efetuada!')\n",
        "print('\\033[1;32mTamanho base de treino (linhas, colunas):')\n",
        "print('\\033[0m'+ str(x_treino.shape))\n",
        "print('\\033[1;32mTamanho base de teste (linhas, colunas):')\n",
        "print('\\033[0m'+ str(x_teste.shape))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vXdBzhEKuYBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a026a5e-a3f7-40cf-8c5e-a299e111faf9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDivisão efetuada!\n",
            "\u001b[1;32mTamanho base de treino (linhas, colunas):\n",
            "\u001b[0m(4188, 43)\n",
            "\u001b[1;32mTamanho base de teste (linhas, colunas):\n",
            "\u001b[0m(1796, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 3: Aplicação dos algoritmos de Machine Leaning</font>"
      ],
      "metadata": {
        "id": "5u4A3faaHvTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste projeto será utilizado os principais algoritmos de classificação para aprendizado supervisionado, sendo eles:\n",
        "* Naive Bayes\n",
        "* SVM (Máquina de Vetor de Suporte)\n",
        "* Regressão Logística\n",
        "* KNN (K Vizinhos Próximos)\n",
        "* Árvore de Decisão\n",
        "* Random Forest\n",
        "* XGBoost\n",
        "* Light GBM\n",
        "\n",
        "\n",
        "Alguns algoritmos disponibilizam configuração de hiperparâmetros para otimização de resultados. \n",
        "\n",
        "> ## ATENÇÃO!!! \n",
        "É possível rodar todos os algoritmos de uma única vez minimizando as células seguintes com a seta ao lado.\n",
        "Todos os hiperparâmetros já estão estão configurados como default.\n"
      ],
      "metadata": {
        "id": "Rb3QICitIAJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Naive Bayes</font>"
      ],
      "metadata": {
        "id": "Co1JeykiQqmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown Naive Bayes é um método probabilístico utilizado para classificar dados em categorias. Ele utiliza o Teorema de Bayes para calcular a probabilidade de um dado pertencer a uma determinada categoria com base nas probabilidades condicionais dos atributos que o caracterizam.\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "print('\\033[1;32mProcessando Naive Bayes...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "\n",
        "# Importando as biliotecas:\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Treinando o algoritmo:\n",
        "naive = GaussianNB()\n",
        "naive.fit(x_treino,y_treino)\n",
        "\n",
        "# Usando base de teste\n",
        "previsoes_naive = naive.predict(x_teste)\n",
        "\n",
        "# Usando base de treino\n",
        "previsoes_treino = naive.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_naive)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_naive)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_naive)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Importando as bibliotecas para Validação Cruzada\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo\n",
        "modelo_nbayes = GaussianNB()\n",
        "resultado_nbayes = cross_val_score(modelo_nbayes,previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_nbayes.mean()*100)))\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mNaive Bayes finalizado!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "biA8zoGnYCBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0202c492-ac75-45ff-9763-0bc03ee84af8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando Naive Bayes...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m68.26%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m69.15%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[842 498]\n",
            " [ 72 384]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[1924 1133]\n",
            " [ 159  972]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.63      0.75      1340\n",
            "           1       0.44      0.84      0.57       456\n",
            "\n",
            "    accuracy                           0.68      1796\n",
            "   macro avg       0.68      0.74      0.66      1796\n",
            "weighted avg       0.80      0.68      0.70      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.63      0.75      3057\n",
            "           1       0.46      0.86      0.60      1131\n",
            "\n",
            "    accuracy                           0.69      4188\n",
            "   macro avg       0.69      0.74      0.67      4188\n",
            "weighted avg       0.80      0.69      0.71      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 68.90%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mNaive Bayes finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> SVM - Máquina de Vetor de Suporte</font>"
      ],
      "metadata": {
        "id": "1emnwJoh70lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown O SVM (Support Vector Machine)  pode ser usado para problemas de classificação e regressão. O objetivo do SVM é encontrar um hiperplano que separe os dados em diferentes classes, maximizando a margem entre os pontos mais próximos de cada classe.\n",
        "\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown > * C: Parâmetro de regularização. Um valor mais alto de C implica em uma classificação mais precisa dos dados de treinamento, mas pode resultar em sobreajuste.\n",
        "#@markdown >\n",
        "#@markdown > #### Informe o valor de C :\n",
        "Valor_C = 60 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "#@markdown >\n",
        "#@markdown > * Kernel: utilizado para mapear os dados de entrada em um espaço de características de maior dimensão. Os kernels comuns são:\n",
        "#@markdown >> * Linear: adequado para problemas de classificação simples onde os dados podem ser linearmente separáveis.\n",
        "#@markdown >> * Polinomial: capaz de separar dados que não são linearmente separáveis, mas pode ser suscetível ao overfitting.\n",
        "#@markdown >> * RBF (Função de Base Radial): capaz de separar dados que não são linearmente separáveis e geralmente produz resultados melhores que o kernel polinomial.\n",
        "#@markdown >> * Sigmoid: adequado para problemas de classificação binária e é especialmente útil para problemas em que os dados têm uma distribuição bimodal.\n",
        "#@markdown >  #### Informe o Kernel:\n",
        "Tipo_Kernel = \"sigmoid\" #@param [\"linear\", \"polynomial\", \"rbf\", \"sigmoid\"]\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando SVM...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando a biblioteca SVM especifico para classificação ( SVC )\n",
        "from sklearn.svm import SVC   \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cria o vetor \"svm\". A configuração kernel para transformar os dados para aplicação da forma correta\n",
        "svm = SVC(kernel=Tipo_Kernel, random_state=1, C= Valor_C) \n",
        "\n",
        "# Criação do fit de treinamento\n",
        "svm.fit(x_treino, y_treino)\n",
        "\n",
        "# Criação do PREVISOR baseado no svm\n",
        "svm_teste =svm.predict(x_teste)\n",
        "\n",
        "# Criação do PREVISOR da base de treino\n",
        "svm_treino = svm.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, svm_teste)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino, svm_treino)*100))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, svm_teste)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, svm_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, svm_teste)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,svm_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "#Criando o modelo\n",
        "modelo_svm=SVC(kernel= Tipo_Kernel,random_state=1,C= Valor_C)\n",
        "resultado_svm= cross_val_score(modelo_svm, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_svm.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mSVM finalizado!')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0JiCmimO7xmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625fef54-63cc-4b3b-e3c9-1682cb93c7a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando SVM...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m73.39%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m72.71%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1095  245]\n",
            " [ 233  223]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2487  570]\n",
            " [ 573  558]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      1340\n",
            "           1       0.48      0.49      0.48       456\n",
            "\n",
            "    accuracy                           0.73      1796\n",
            "   macro avg       0.65      0.65      0.65      1796\n",
            "weighted avg       0.74      0.73      0.73      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81      3057\n",
            "           1       0.49      0.49      0.49      1131\n",
            "\n",
            "    accuracy                           0.73      4188\n",
            "   macro avg       0.65      0.65      0.65      4188\n",
            "weighted avg       0.73      0.73      0.73      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 72.66%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mSVM finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Regressão Logística</font>"
      ],
      "metadata": {
        "id": "4GMvfo4rl9yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown A Regressão Logística é um algoritmo de aprendizado de máquina utilizado para classificação binária, ou seja, para prever se uma observação pertence a uma das duas categorias possíveis (por exemplo, sim ou não, verdadeiro ou falso, etc.).\n",
        "\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Iter:\n",
        "#@markdown  Define o número máximo de iterações para o algoritmo convergir. Este parâmetro controla a quantidade de tempo que o modelo terá para encontrar o melhor conjunto de pesos.\n",
        "#@markdown >\n",
        "#@markdown >  #### Informe o valor de Max_Iter :\n",
        "Valor_Max_Iter = 500 #@param {type:\"slider\", min:20, max:1000, step:20}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Penalty:\n",
        "#@markdown  Define o tipo de regularização que será aplicada ao modelo. A regularização é uma técnica que ajuda a prevenir overfitting, penalizando coeficientes muito grandes. Opções:\n",
        "#@markdown * l1: Adiciona uma penalidade igual à soma dos valores absolutos dos coeficientes. Essa opção pode ser usada para selecionar recursos importantes do modelo, tornando os outros coeficientes iguais a zero.\n",
        "#@markdown * l2: Regularização L2: Adiciona uma penalidade igual à soma dos quadrados dos coeficientes. Essa opção pode ser usada para evitar overfitting, tornando os coeficientes pequenos, mas não necessariamente iguais a zero.\n",
        "#@markdown >  #### Informe o Penalty:\n",
        "Tipo_Penalty = \"l2\" #@param [\"l1\", \"l2\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### C:\n",
        "#@markdown  Define o inverso da força da regularização. Quanto maior o valor de C, menos regularização é aplicada. Este parâmetro pode ser usado para controlar o trade-off entre o viés e a variância do modelo.\n",
        "#@markdown > #### Informe o valor de C:\n",
        "Valor_C = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Solver:\n",
        "#@markdown  Define o algoritmo a ser utilizado no processo de otimização. Opções:\n",
        "#@markdown * newton-cg: É eficiente para dados com muitas amostras e muitas características, mas pode ser lento para conjuntos de dados muito grandes. <font color='#FFFF00'> Somente para Penalty l2 </font>\n",
        "#@markdown * lbfgs: É uma opção mais rápida que o solver \"newton-cg\" e é adequado para conjuntos de dados com muitas amostras e poucas características. <font color='#FFFF00'> Somente para Penalty l2 </font>\n",
        "#@markdown * liblinear: É uma opção mais rápida para conjuntos de dados pequenos e médios, mas pode ter dificuldades para convergir em conjuntos de dados muito grandes.\n",
        "#@markdown * saga: É adequado para conjuntos de dados grandes, mas pode ter dificuldades para convergir em problemas com regularização L1.\n",
        "\n",
        "#@markdown >  #### Informe o Solver:\n",
        "Tipo_Solver = \"lbfgs\" #@param [\"newton-cg\", \"lbfgs\", \"liblinear\", \"saga\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando Regressão Logística...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo\n",
        "logistica = LogisticRegression(random_state=1,max_iter= Valor_Max_Iter, penalty= Tipo_Penalty,tol=0.0001, C= Valor_C, solver= Tipo_Solver)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "logistica.fit(x_treino,y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_logistica = logistica.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino= logistica.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste,previsoes_logistica)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, previsoes_logistica)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, previsoes_logistica)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "#Criando o modelo\n",
        "#Criando o modelo\n",
        "modelo_rl=LogisticRegression(random_state=1,max_iter= Valor_Max_Iter, penalty= Tipo_Penalty,tol=0.0001, C= Valor_C, solver= Tipo_Solver)\n",
        "resultado_rl= cross_val_score(modelo_rl, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_rl.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRegressão Logística finalizada!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7mjxzBR9wXYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390b186e-b638-4459-f08a-7f4cc8345e63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando Regressão Logística...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m78.79%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m80.44%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1182  158]\n",
            " [ 223  233]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2749  308]\n",
            " [ 511  620]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86      1340\n",
            "           1       0.60      0.51      0.55       456\n",
            "\n",
            "    accuracy                           0.79      1796\n",
            "   macro avg       0.72      0.70      0.71      1796\n",
            "weighted avg       0.78      0.79      0.78      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      3057\n",
            "           1       0.67      0.55      0.60      1131\n",
            "\n",
            "    accuracy                           0.80      4188\n",
            "   macro avg       0.76      0.72      0.74      4188\n",
            "weighted avg       0.80      0.80      0.80      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 79.78%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRegressão Logística finalizada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> KNN</font>"
      ],
      "metadata": {
        "id": "O2u6qMQhzfdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown O objetivo do KNN é classificar uma amostra desconhecida com base nas classes de exemplos de treinamento mais próximos. Isso é feito calculando a distância entre a amostra desconhecida e todos os exemplos de treinamento no espaço de recursos e selecionando os k exemplos de treinamento mais próximos. A classe mais comum entre esses k exemplos é então atribuída à amostra desconhecida.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### N_Neighbors:\n",
        "#@markdown  é um dos principais parâmetros do algoritmo KNN (K-Nearest Neighbors). Ele controla o número de vizinhos mais próximos que serão considerados para determinar a classe de uma nova amostra. Em outras palavras, o valor de n_neighbors define o tamanho do subconjunto de amostras de treinamento que serão usadas para tomar uma decisão sobre a classe de uma nova amostra.\n",
        "#@markdown >\n",
        "#@markdown >  #### Informe o valor de N_Neighbors :\n",
        "Valor_N_Neighbors = 30 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Metric:\n",
        "#@markdown  Metric controla a métrica de distância que será utilizada para medir a distância entre as amostras do conjunto de treinamento e a nova amostra a ser classificada. Opções:\n",
        "#@markdown * euclidean: mede a distância entre dois pontos em um espaço euclidiano, definida pela raiz quadrada da soma dos quadrados das diferenças entre as coordenadas dos dois pontos.\n",
        "#@markdown * manhattan: mede a distância entre dois pontos ao longo dos eixos, em vez de uma linha reta. A distância Manhattan é definida pela soma das diferenças absolutas entre as coordenadas dos dois pontos.\n",
        "#@markdown * chebyshev: mede a distância máxima ao longo de qualquer dimensão entre dois pontos. É definida como o valor absoluto da diferença máxima entre as coordenadas dos dois pontos.\n",
        "#@markdown * minkowski: é uma métrica de distância geral que inclui a distância Euclidiana e a distância de Manhattan como casos especiais. \n",
        "#@markdown * cosine: calcula a similaridade entre duas amostras, em vez da distância. É útil para dados esparsos e para dados onde a magnitude das características é irrelevante.\n",
        "\n",
        "#@markdown >  #### Informe o Metric:\n",
        "Tipo_Metric = \"cosine\" #@param [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\", \"cosine\"]\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando KNN...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. Se metrics for minkowski recebe um componente adicional p\n",
        "if Tipo_Metric == 'minkowski':\n",
        "    knn = KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric='minkowski',p=2,)\n",
        "else:\n",
        "    knn = KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric=Tipo_Metric)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "knn.fit(x_treino,y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_knn = knn.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino= knn.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_knn)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_knn)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_knn)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "\n",
        "# Criando o modelo. Se metrics for minkowski recebe um componente adicional p\n",
        "if Tipo_Metric == 'minkowski':\n",
        "    modelo_knn= KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric='minkowski',p=2,)\n",
        "else:\n",
        "    modelo_knn= KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric=Tipo_Metric)\n",
        "\n",
        "resultado_knn =cross_val_score(modelo_knn, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_knn.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mKNN finalizada!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z8ELCQY_zZGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45db7a60-14af-4a1a-983a-68ed3658da09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando KNN...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m77.51%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m79.85%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1159  181]\n",
            " [ 223  233]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2711  346]\n",
            " [ 498  633]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85      1340\n",
            "           1       0.56      0.51      0.54       456\n",
            "\n",
            "    accuracy                           0.78      1796\n",
            "   macro avg       0.70      0.69      0.69      1796\n",
            "weighted avg       0.77      0.78      0.77      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87      3057\n",
            "           1       0.65      0.56      0.60      1131\n",
            "\n",
            "    accuracy                           0.80      4188\n",
            "   macro avg       0.75      0.72      0.73      4188\n",
            "weighted avg       0.79      0.80      0.79      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 78.39%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mKNN finalizada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Árvore de Decisão</font>"
      ],
      "metadata": {
        "id": "PYbxHBVXj0AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Árvore de decisão é um modelo de aprendizado de máquina supervisionado que pode ser usado tanto para tarefas de classificação quanto de regressão. A árvore de decisão divide o conjunto de dados em subconjuntos menores, com base nos valores das variáveis ​​explicativas, para prever a variável de resposta.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Criterion:\n",
        "#@markdown  é usado na árvore de decisão para definir o critério de avaliação da qualidade da divisão em cada nó da árvore. Existem dois critérios populares usados na árvore de decisão:\n",
        "#@markdown * gini: O critério de impureza de Gini mede a probabilidade de classificar incorretamente uma amostra aleatória com base na distribuição das classes naquele nó. Quanto menor o valor da impureza de Gini, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown * entropy: O critério de entropia mede a incerteza da classificação em um determinado nó. Ele é calculado como a soma ponderada do logaritmo da probabilidade de cada classe, multiplicado pela probabilidade negativa. Quanto menor o valor da entropia, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown >  #### Informe o valor de Criterion :\n",
        "Tipo_Criterion = \"entropy\" #@param [\"gini\", \"entropy\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown  hiperparâmetro importante na árvore de decisão que controla a profundidade máxima da árvore. A profundidade de uma árvore de decisão é medida pelo número de ramos que precisamos seguir a partir da raiz para chegar a um nó folha.\n",
        "\n",
        "#@markdown Limitar a profundidade da árvore pode ajudar a evitar o sobreajuste (overfitting) do modelo. Isso significa que, ao limitar a profundidade máxima da árvore, estamos impedindo que a árvore se torne muito complexa e especializada no conjunto de treinamento específico.\n",
        "\n",
        "#@markdown No entanto, definir um valor muito baixo para max_depth pode resultar em subajuste (underfitting), onde o modelo não é complexo o suficiente para capturar padrões importantes no conjunto de dados.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Max_Depth:\n",
        "Valor_Max_Depth = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando Árvore de Decisão...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. \n",
        "arvore = DecisionTreeClassifier(criterion= Tipo_Criterion,random_state=0,max_depth= Valor_Max_Depth)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "arvore.fit(x_treino,y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_arvore = arvore.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino = arvore.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste,previsoes_arvore)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_arvore)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_arvore)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo_ad =DecisionTreeClassifier(criterion= Tipo_Criterion,random_state=0,max_depth= Valor_Max_Depth)\n",
        "\n",
        "resultado_ad =cross_val_score(modelo_ad, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_ad.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mÁrvore de Decisão Finalizada!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "huW-rIEgj0ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddd39c4-0324-460d-c498-b449af7c596c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando Árvore de Decisão...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m78.34%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m80.06%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1203  137]\n",
            " [ 252  204]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2792  265]\n",
            " [ 570  561]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86      1340\n",
            "           1       0.60      0.45      0.51       456\n",
            "\n",
            "    accuracy                           0.78      1796\n",
            "   macro avg       0.71      0.67      0.69      1796\n",
            "weighted avg       0.77      0.78      0.77      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87      3057\n",
            "           1       0.68      0.50      0.57      1131\n",
            "\n",
            "    accuracy                           0.80      4188\n",
            "   macro avg       0.75      0.70      0.72      4188\n",
            "weighted avg       0.79      0.80      0.79      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 78.36%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mÁrvore de Decisão Finalizada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Random Forest</font>\n"
      ],
      "metadata": {
        "id": "hA6z_mhF3hGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown É um algoritmo que combina várias árvores de decisão para fazer previsões. É altamente preciso e pode lidar com conjuntos de dados grandes com características de alta dimensão. Um aspecto importante do algoritmo Random Forest é a sua capacidade de evitar overfitting. \n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### N_Estimators:\n",
        "#@markdown  este é o número de árvores de decisão a serem construídas pelo algoritmo. Valores mais altos podem levar a um modelo mais preciso, mas também aumentam o risco de overfitting.\n",
        "#@markdown >  #### Informe o valor de Max_Depth :\n",
        "Valor_N_Estimators = 500 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Criterion:\n",
        "#@markdown  é usado na árvore de decisão para definir o critério de avaliação da qualidade da divisão em cada nó da árvore. Existem dois critérios populares usados na árvore de decisão:\n",
        "#@markdown * gini: O critério de impureza de Gini mede a probabilidade de classificar incorretamente uma amostra aleatória com base na distribuição das classes naquele nó. Quanto menor o valor da impureza de Gini, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown * entropy: O critério de entropia mede a incerteza da classificação em um determinado nó. Ele é calculado como a soma ponderada do logaritmo da probabilidade de cada classe, multiplicado pela probabilidade negativa. Quanto menor o valor da entropia, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown >  #### Informe o valor de Criterion :\n",
        "Tipo_Criterion = \"entropy\" #@param [\"gini\", \"entropy\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown   é a profundidade máxima que cada árvore de decisão pode atingir. Árvores mais profundas podem capturar mais detalhes nos dados, mas também podem levar a overfitting.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Max_Depth:\n",
        "Valor_Max_Depth = 7 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando Random Forest...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. \n",
        "random = RandomForestClassifier(n_estimators= Valor_N_Estimators, criterion= Tipo_Criterion, random_state = 0, max_depth= Valor_Max_Depth)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "random.fit(x_treino, y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_random = random.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino = random.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_random)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino, previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, previsoes_random)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, previsoes_random)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo_rf = RandomForestClassifier(n_estimators= Valor_N_Estimators, criterion= Tipo_Criterion, random_state = 0, max_depth= Valor_Max_Depth)\n",
        "\n",
        "resultado_rf = cross_val_score(modelo_rf, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_rf.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRandom Forest Finalizado!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OZ0v8QXI3gEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbda4f7-6db9-4c87-dd46-b7929babfc41"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando Random Forest...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m79.45%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m82.09%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1210  130]\n",
            " [ 239  217]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2829  228]\n",
            " [ 522  609]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1340\n",
            "           1       0.63      0.48      0.54       456\n",
            "\n",
            "    accuracy                           0.79      1796\n",
            "   macro avg       0.73      0.69      0.70      1796\n",
            "weighted avg       0.78      0.79      0.78      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88      3057\n",
            "           1       0.73      0.54      0.62      1131\n",
            "\n",
            "    accuracy                           0.82      4188\n",
            "   macro avg       0.79      0.73      0.75      4188\n",
            "weighted avg       0.81      0.82      0.81      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 79.98%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRandom Forest Finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> XGBOOST</font>"
      ],
      "metadata": {
        "id": "9SBBVBHD8XxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Algoritmo de aprendizado de máquina baseado em árvores de decisão que foi desenvolvido para melhorar o desempenho do Gradient Boosting. O XGBoost funciona através da criação de um conjunto de árvores de decisão sequenciais, onde cada nova árvore é treinada para corrigir os erros do modelo anterior. Isso é conhecido como boosting, que é um método de aprendizado em que os modelos mais fracos são combinados para criar um modelo mais forte.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown  a profundidade máxima de cada árvore. Valores mais altos podem levar a um modelo mais preciso, mas também aumentam o risco de overfitting.\n",
        "#@markdown >  #### Informe o valor de Max_Depth :\n",
        "Valor_Max_Depth = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Learning_Rate:\n",
        "#@markdown  a taxa de aprendizado do modelo. Valores menores podem levar a uma melhor precisão do modelo, mas também aumentam o tempo de treinamento.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Learning_Rate:\n",
        "Valor_Learning_Rate = 0.5 #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### N_Estimators :\n",
        "#@markdown  especifica o número de árvores de decisão que serão criadas no modelo. Cada árvore é adicionada sequencialmente ao modelo e visa corrigir os erros do modelo anterior. Um valor muito baixo pode resultar em um modelo impreciso, enquanto um valor muito alto pode resultar em overfitting e um modelo que não generaliza bem para novos dados.\n",
        "\n",
        "#@markdown >  #### Informe o valor de N_Estimators:\n",
        "Valor_N_Estimators = 50 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Objective :\n",
        "#@markdown  especifica a função objetivo a ser otimizada durante o treinamento do modelo. A escolha da função objetivo depende do tipo de problema que está sendo abordado, como regressão ou classificação binária/multiclasse. Opções:\n",
        "#@markdown * reg:squarederror: Erro quadrático médio para problemas de regressão.\n",
        "#@markdown * reg:logistic: Função de perda de regressão logística para problemas de classificação binária.\n",
        "#@markdown * binary:logistic:  Função de perda de regressão logística para problemas de classificação binária.\n",
        "#@markdown * multi:softmax: Função de perda de entropia cruzada para problemas de classificação multiclasse.\n",
        "#@markdown * rank:pairwise: Função de perda de classificação para problemas de classificação de ranking.\n",
        "\n",
        "#@markdown >  #### Informe o tipo de Objective:\n",
        "Tipo_Objective = \"reg:logistic\" #@param [\"reg:squarederror\", \"reg:logistic\", \"binary:logistic\", \"multi:softmax\", \"rank:pairwise\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando XGBOOST...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. \n",
        "xg=XGBClassifier(max_depth= Valor_Max_Depth, learning_rate= Valor_Learning_Rate, n_estimators= Valor_N_Estimators, objective=Tipo_Objective, random_state=3)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "xg.fit(x_treino, y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_xg = xg.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino=xg.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste,previsoes_xg)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_xg)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_xg)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo_xgboost =XGBClassifier(max_depth= Valor_Max_Depth, learning_rate= Valor_Learning_Rate, n_estimators= Valor_N_Estimators, objective=Tipo_Objective, random_state=3)\t\t\n",
        "\n",
        "resultado_xgboost = cross_val_score(modelo_xgboost, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_xgboost.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mXGBOOST Finalizado!')"
      ],
      "metadata": {
        "id": "WZ9pWBfN8YbI",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325f5cae-39ac-4f48-d9d3-8de5b9af312b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando XGBOOST...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m79.84%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m81.95%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1203  137]\n",
            " [ 225  231]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2795  262]\n",
            " [ 494  637]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1340\n",
            "           1       0.63      0.51      0.56       456\n",
            "\n",
            "    accuracy                           0.80      1796\n",
            "   macro avg       0.74      0.70      0.71      1796\n",
            "weighted avg       0.79      0.80      0.79      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88      3057\n",
            "           1       0.71      0.56      0.63      1131\n",
            "\n",
            "    accuracy                           0.82      4188\n",
            "   macro avg       0.78      0.74      0.75      4188\n",
            "weighted avg       0.81      0.82      0.81      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 80.28%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mXGBOOST Finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> LightGBM</font>"
      ],
      "metadata": {
        "id": "YRj2kQHf89pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1;32mProcessando LightGBM...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "#@markdown Algoritmo de aprendizado de máquina baseado em árvore que se destaca pela sua eficiência e escalabilidade. Ele usa uma técnica chamada \"histograma de decisão\" para construir as árvores de decisão, o que torna a construção das árvores muito mais rápida do que os algoritmos tradicionais de árvore de decisão.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Num_Boost_Round :\n",
        "#@markdown é um parâmetro no LightGBM, que especifica o número máximo de iterações de treinamento que serão realizadas para ajustar o modelo. Cada iteração adiciona uma nova árvore ao modelo, de modo que aumentar o número de iterações aumenta a complexidade do modelo.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Num_Boost_Round:\n",
        "Valor_Num_Boost_Round = 20 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown  este é o limite máximo de profundidade da árvore. Quanto mais profunda a árvore, mais complexa ela será e mais fácil será para o modelo memorizar os dados de treinamento. No entanto, um número muito grande de profundidade pode levar ao overfitting.\n",
        "#@markdown >  #### Informe o valor de Max_Depth :\n",
        "Valor_Max_Depth = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Learning_Rate:\n",
        "#@markdown  a taxa de aprendizado do modelo. Valores menores podem levar a uma melhor precisão do modelo, mas também aumentam o tempo de treinamento.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Learning_Rate:\n",
        "Valor_Learning_Rate = 0.2 #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Num_Leaves :\n",
        "#@markdown  este é o número máximo de folhas permitidas em uma árvore. Quanto maior o número de folhas, mais complexa será a árvore e mais fácil será para o modelo memorizar os dados de treinamento. No entanto, um número muito grande de folhas pode levar ao overfitting.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Num_Leaves:\n",
        "Valor_Num_Leaves = 50 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Bins :\n",
        "#@markdown  este é o número máximo de bins (intervalos) que serão usados para discretizar as variáveis contínuas. A discretização ajuda a lidar com valores extremos e a reduzir o impacto de outliers nos dados. Um número maior de bins pode levar a uma melhor precisão, mas também pode levar a overfitting.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Max_Bins:\n",
        "Valor_Max_Bins = 250 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Objective :\n",
        "#@markdown  é usado para especificar a função de perda que o modelo irá otimizar durante o treinamento. Opções:\n",
        "#@markdown * binary: Usado para problemas de classificação binária. O modelo tenta otimizar a log-verossimilhança binária.\n",
        "#@markdown * multiclass: Usado para problemas de classificação multiclasse. O modelo tenta otimizar a log-verossimilhança softmax.\n",
        "#@markdown * multiclassova:  Usado para problemas de classificação multiclasse. O modelo trata cada classe como um problema de classificação binária e tenta otimizar a log-verossimilhança binária para cada classe.\n",
        "#@markdown * cross_entropy: Usado para problemas de classificação binária ou multiclasse. O modelo tenta minimizar a entropia cruzada entre as distribuições de probabilidade previstas e as distribuições de probabilidade verdadeiras.\n",
        "#@markdown * xentropy: Também usado para problemas de classificação binária ou multiclasse, esta opção é semelhante à cross_entropy`, mas usa uma versão mais eficiente do cálculo da entropia cruzada.\n",
        "\n",
        "#@markdown >  #### Informe o tipo de Objective:\n",
        "Tipo_Objective = \"cross_entropy\" #@param [\"binary\", \"multiclass\", \"multiclassova\", \"cross_entropy\", \"xentropy\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "\n",
        "# Importando biblioteca \n",
        "import lightgbm as lgb \n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Dataset para treino\n",
        "dataset = lgb.Dataset(x_treino,label=y_treino)\n",
        "\n",
        "# Parâmetros\n",
        "\n",
        "\n",
        "# Criando o modelo. \n",
        "lgbm = lgb.train(\n",
        "    {'num_leaves': Valor_Num_Leaves,\n",
        "     'objective': Tipo_Objective,\n",
        "     'max_depth': Valor_Max_Depth,\n",
        "     'learning_rate': Valor_Learning_Rate,\n",
        "     'max_bin': Valor_Max_Bins\n",
        "    },\n",
        "    dataset,\n",
        "    num_boost_round=Valor_Num_Boost_Round\n",
        ")\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_lgbm = lgbm.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino = lgbm.predict(x_treino)\n",
        "\n",
        "# Base de teste: Quando for menor que 5 considera 0 e quando for maior ou igual a 5 considera 1\n",
        "for i in range(0, len(previsoes_lgbm)):\n",
        "    if previsoes_lgbm[i] >= 0.5:       \n",
        "       previsoes_lgbm[i] = 1\n",
        "    else:  \n",
        "       previsoes_lgbm[i] = 0\n",
        "\n",
        "# Base de treino: Quando for menor que 5 considera 0 e quando for maior ou igual a 5 considera 1\n",
        "for i in range(0, len(previsoes_treino)):\n",
        "    if previsoes_treino[i] >= 0.5:       \n",
        "       previsoes_treino[i] = 1\n",
        "    else:  \n",
        "       previsoes_treino[i] = 0\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_lgbm)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino, previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, previsoes_lgbm)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, previsoes_lgbm)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo_lgbm = lgb.LGBMClassifier(num_leaves = Valor_Num_Leaves, objective = Tipo_Objective,     \n",
        "                            max_depth = Valor_Max_Depth, learning_rate = Valor_Learning_Rate, max_bin =Valor_Max_Bins)\n",
        "\n",
        "resultado_lgbm = cross_val_score(modelo_lgbm, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_lgbm.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mLightGBM Finalizado!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JiOElKZC9Fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669f059f-92ee-4a9d-bef6-d3da32f77015"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando LightGBM...\n",
            "\u001b[0m=======================================================\n",
            "[LightGBM] [Info] [cross_entropy:Init]: (objective) labels passed interval [0, 1] check\n",
            "[LightGBM] [Info] [cross_entropy:Init]: (metric) labels passed interval [0, 1] check\n",
            "[LightGBM] [Info] [cross_entropy:Init]: sum-of-weights = 4188.000000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 395\n",
            "[LightGBM] [Info] Number of data points in the train set: 4188, number of used features: 43\n",
            "[LightGBM] [Info] [cross_entropy:BoostFromScore]: pavg = 0.270057 -> initscore = -0.994332\n",
            "[LightGBM] [Info] Start training from score -0.994332\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m78.73%\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m80.49%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[1221  119]\n",
            " [ 263  193]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[2830  227]\n",
            " [ 590  541]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86      1340\n",
            "           1       0.62      0.42      0.50       456\n",
            "\n",
            "    accuracy                           0.79      1796\n",
            "   macro avg       0.72      0.67      0.68      1796\n",
            "weighted avg       0.77      0.79      0.77      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.87      3057\n",
            "           1       0.70      0.48      0.57      1131\n",
            "\n",
            "    accuracy                           0.80      4188\n",
            "   macro avg       0.77      0.70      0.72      4188\n",
            "weighted avg       0.79      0.80      0.79      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 80.33%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mLightGBM Finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 4: Comparando o desempenho dos algoritmos</font>"
      ],
      "metadata": {
        "id": "9ZSEb_AopRXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'>Acurácia</font>"
      ],
      "metadata": {
        "id": "PfClR8IZrF4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Compare a Acurácia dos Algoritmos. \n",
        "#@markdown  * Acurácia é a métrica que mede a proporção de predições corretas feitas pelo modelo em relação ao total de predições feitas. Em outras palavras, a acurácia indica a porcentagem de vezes que o modelo classificou corretamente as amostras de dados.\n",
        "#@markdown ### Atenção! \n",
        "#@markdown A Acurácia não é a principal métrica de avaliação e deve ser avaliada em conjunto com outras métricas.\n",
        "\n",
        "# Importando bibliotecas\n",
        "import plotly.graph_objs as go\n",
        "#==============================================================\n",
        "# Atribuindo médias para resultados de acuracia:\n",
        "Naive_Bayes = (sum(resultado_nbayes) / len(resultado_nbayes)) \n",
        "S_V_M = (sum(resultado_svm) / len(resultado_svm)) \n",
        "Reg_Logistica = (sum(resultado_rl) / len(resultado_rl)) \n",
        "K_N_N = (sum(resultado_knn) / len(resultado_knn)) \n",
        "Arv_Decisao = (sum(resultado_ad) / len(resultado_ad)) \n",
        "R_Forest = (sum(resultado_rf) / len(resultado_rf)) \n",
        "XG_BOOST = (sum(resultado_xgboost) / len(resultado_xgboost)) \n",
        "Light_GBM = (sum(resultado_lgbm) / len(resultado_lgbm)) \n",
        "\n",
        "# Criando lista com acurácias\n",
        "acuracia = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "maior_acuracia = max(acuracia)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "#cores = ['red' if acuracia[i] == maior_acuracia else 'blue' for i in range(len(acuracia))]\n",
        "cores = ['blue'] * len(acuracia)\n",
        "indice_maior_acuracia = acuracia.index(maior_acuracia)\n",
        "cores[indice_maior_acuracia] = 'red'\n",
        "\n",
        "# Criando rótulos para as barras com o valor recall e o percentual correspondente\n",
        "#labels = [f'{acur_perc:.2%}' for nome, acur, acur_perc in zip(nome_algoritmos, acuracia, (acuracia)*100 )]\n",
        "labels = [f'{acur_perc:.2%}' for nome, acur, acur_perc in zip(nome_algoritmos, acuracia, acuracia)]\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=acuracia, marker=dict(color=cores), text=labels, textposition='auto')]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de Acurácia entre os Algoritmos',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='Acurácia'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Og88Gqmomo-z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "7a8a7c40-4327-4ef5-e6be-7db2bad45c8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"64430426-b241-4d07-84ea-47e3fd6de572\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"64430426-b241-4d07-84ea-47e3fd6de572\")) {                    Plotly.newPlot(                        \"64430426-b241-4d07-84ea-47e3fd6de572\",                        [{\"marker\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\"]},\"text\":[\"68.90%\",\"72.66%\",\"79.78%\",\"78.39%\",\"78.36%\",\"79.98%\",\"80.28%\",\"80.33%\"],\"textposition\":\"auto\",\"x\":[\"Naive_Bayes\",\"S_V_M\",\"Reg_Logistica\",\"K_N_N\",\"Arv_Decisao\",\"R_Forest\",\"XG_BOOST\",\"Light_GBM\"],\"y\":[0.6889932998324956,0.7265854271356785,0.79778810720268,0.7839304857621443,0.783605527638191,0.7998115577889446,0.802817420435511,0.8033241206030151],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Compara\\u00e7\\u00e3o de Acur\\u00e1cia entre os Algoritmos\"},\"xaxis\":{\"title\":{\"text\":\"Algoritmos\"}},\"yaxis\":{\"title\":{\"text\":\"Acur\\u00e1cia\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('64430426-b241-4d07-84ea-47e3fd6de572');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'>Precisão</font>"
      ],
      "metadata": {
        "id": "SDjRuyEs9-tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Avalie a Precisão dos Algoritmos\n",
        "#@markdown > * Precisão é uma métrica que mede a proporção de verdadeiros positivos (TP) em relação a todos os exemplos classificados como positivos (TP + falsos positivos, FP). Em outras palavras, a precision indica quantos casos previstos corretamente foram positivos. Quanto maior a precision, menor a proporção de exemplos que foram erroneamente classificados como positivos.\n",
        "#@markdown ### Situações em que Precisão é muito importante:\n",
        "#@markdown * Detecção de Fraude\n",
        "#@markdown * Risco\n",
        "#@markdown * Marketing\n",
        "\n",
        "# Importando biblioteca:\n",
        "from numpy import mean\n",
        "\n",
        "# Validando o Precisão:\n",
        "Naive_Bayes = mean(cross_val_score(modelo_nbayes,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "S_V_M = mean(cross_val_score(modelo_svm,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "Reg_Logistica = mean(cross_val_score(modelo_rl,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "K_N_N = mean(cross_val_score(modelo_knn,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "Arv_Decisao = mean(cross_val_score(modelo_ad,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "R_Forest = mean(cross_val_score(modelo_rf,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "XG_BOOST = mean(cross_val_score(modelo_xgboost,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "Light_GBM = mean(cross_val_score(modelo_lgbm,previsores_esc,alvo,cv=kfold, scoring='precision'))\n",
        "\n",
        "\n",
        "# Criando lista com precision score\n",
        "lista_precision = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "maior_precision = max(lista_precision)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "#cores = ['red' if acuracia[i] == maior_acuracia else 'blue' for i in range(len(acuracia))]\n",
        "cores = ['blue'] * len(lista_precision)\n",
        "indice_maior_precision = lista_precision.index(maior_precision)\n",
        "cores[indice_maior_precision] = 'red'\n",
        "\n",
        "# Criando rótulos para as barras com o valor precision e o percentual correspondente\n",
        "labels = [f'{precision_perc:.2%}' for nome, pecision, precision_perc in zip(nome_algoritmos, lista_precision, (lista_precision)*100 )]\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=lista_precision, marker=dict(color=cores),text=labels,textposition='auto')]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de Precisão entre os Algoritmos',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='Precisão'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZTEiKkIw-Gj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'>Recall</font>"
      ],
      "metadata": {
        "id": "OvwP42cYFYj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Avalie o Recall dos Algoritmos\n",
        "#@markdown > * Recall é uma métrica que mede a capacidade do modelo em identificar corretamente os verdadeiros positivos, ou seja, quantos exemplos positivos reais conseguimos prever com o modelo. Útil em casos que Falso Negativo supera Falso Positivo.\n",
        "#@markdown ### Situações em que Precisão é muito importante:\n",
        "#@markdown * Detecção de fraudes financeiras\n",
        "#@markdown * Diagnóstico médico, pois um falso negativo pode levar um paciente a morte\n",
        "#@markdown * Diagnóstico de falhas em equipamentos\n",
        "\n",
        "# Importando biblioteca:\n",
        "from numpy import mean\n",
        "\n",
        "# Validando o Precisão:\n",
        "Naive_Bayes = mean(cross_val_score(modelo_nbayes,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "S_V_M = mean(cross_val_score(modelo_svm,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "Reg_Logistica = mean(cross_val_score(modelo_rl,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "K_N_N = mean(cross_val_score(modelo_knn,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "Arv_Decisao = mean(cross_val_score(modelo_ad,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "R_Forest = mean(cross_val_score(modelo_rf,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "XG_BOOST = mean(cross_val_score(modelo_xgboost,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "Light_GBM = mean(cross_val_score(modelo_lgbm,previsores_esc,alvo,cv=kfold, scoring='recall'))\n",
        "\n",
        "# Criando lista com recall score\n",
        "lista_recall = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "maior_recall = max(lista_recall)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "#cores = ['red' if acuracia[i] == maior_acuracia else 'blue' for i in range(len(acuracia))]\n",
        "cores = ['blue'] * len(lista_recall)\n",
        "indice_maior_Recall = lista_recall.index(maior_recall)\n",
        "cores[indice_maior_Recall] = 'red'\n",
        "\n",
        "# Criando rótulos para as barras com o valor recall e o percentual correspondente\n",
        "labels = [f'{recall_perc:.2%}' for nome, recall, recall_perc in zip(nome_algoritmos, lista_recall, (lista_recall)*100 )]\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=lista_recall, marker=dict(color=cores), text=labels, textposition='auto')]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de Recall entre os Algoritmos',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='Recall'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "45f_N85RFY2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'>F1-Score</font>"
      ],
      "metadata": {
        "id": "IM4ocUGAtCU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Avalie o F1-Score dos Algoritmos\n",
        "#@markdown > * O F1-score é uma métrica que combina as métricas de precisão e recall em uma única medida. Ele é útil quando há um desequilíbrio nas classes de dados, onde uma classe é mais frequente do que a outra.\n",
        "\n",
        "# Importando biblioteca:\n",
        "from numpy import mean\n",
        "# Validando o f1\n",
        "scores_nbayes = cross_val_score(modelo_nbayes,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "Naive_Bayes = mean(scores_nbayes)\n",
        "scores_svm = cross_val_score(modelo_svm,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "S_V_M = mean(scores_svm)\n",
        "scores_rl = cross_val_score(modelo_rl,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "Reg_Logistica = mean(scores_rl)\n",
        "scores_knn = cross_val_score(modelo_knn,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "K_N_N = mean(scores_knn)\n",
        "scores_ad = cross_val_score(modelo_ad,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "Arv_Decisao = mean(scores_ad)\n",
        "scores_rf = cross_val_score(modelo_rf,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "R_Forest = mean(scores_rf)\n",
        "scores_xgboost = cross_val_score(modelo_xgboost,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "XG_BOOST = mean(scores_xgboost)\n",
        "scores_lgbm = cross_val_score(modelo_lgbm,previsores_esc,alvo,cv=kfold, scoring='f1_macro')\n",
        "Light_GBM = mean(scores_lgbm)\n",
        "\n",
        "# Criando lista com f1 score\n",
        "lista_f1 = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "maior_f1 = max(lista_f1)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "#cores = ['red' if acuracia[i] == maior_acuracia else 'blue' for i in range(len(acuracia))]\n",
        "cores = ['blue'] * len(lista_f1)\n",
        "indice_maior_f1 = lista_f1.index(maior_f1)\n",
        "cores[indice_maior_f1] = 'red'\n",
        "\n",
        "# Criando rótulos para as barras com o valor F1 e o percentual correspondente\n",
        "labels = [f'{f1_perc:.2%}' for nome, f1, f1_perc in zip(nome_algoritmos, lista_f1,(lista_f1) *100 )]\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=lista_f1, marker=dict(color=cores), text=labels, textposition='auto')]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de F1 Score entre os Algoritmos',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='F1 Score'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d10NXvqT0t6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'>Falsos Positivos</font> - Erro Tipo I"
      ],
      "metadata": {
        "id": "oXXyiL5iu8zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Avalie Falsos Positivos dos Algoritmos\n",
        "#@markdown > * Falsos positivos ocorrem quando um classificador prevê incorretamente que uma entrada pertence a uma determinada classe, quando na verdade não pertence, gerando um Erro do Tipo 1.\n",
        "\n",
        "#@markdown > Os falsos positivos podem ser problemáticos em muitos contextos. Por exemplo, em diagnósticos médicos, um falso positivo pode levar a um tratamento desnecessário e caro, além de causar estresse e ansiedade desnecessários para o paciente. Em segurança cibernética, um falso positivo pode levar a uma interrupção desnecessária nos sistemas e à perda de tempo e recursos da equipe de segurança.\n",
        "\n",
        "#@markdown #### IMPORTANTE: considere o algoritmo com menor taxa de Falsos Positivos\n",
        "\n",
        "# Importando biblioteca:\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# Validando o FP\n",
        "N_Bayes_Predict = cross_val_predict(modelo_nbayes,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, N_Bayes_Predict).ravel()\n",
        "Naive_Bayes = fp / (fp + tn)\n",
        "\n",
        "SVM_Predict = cross_val_predict(modelo_svm,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, SVM_Predict).ravel()\n",
        "S_V_M = fp / (fp + tn)\n",
        "\n",
        "RL_Predict = cross_val_predict(modelo_rl,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, RL_Predict).ravel()\n",
        "Reg_Logistica = fp / (fp + tn)\n",
        "\n",
        "KNN_Predict = cross_val_predict(modelo_knn,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, KNN_Predict).ravel()\n",
        "K_N_N = fp / (fp + tn)\n",
        "\n",
        "AD_Predict = cross_val_predict(modelo_ad,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, AD_Predict).ravel()\n",
        "Arv_Decisao = fp / (fp + tn)\n",
        "\n",
        "RF_Predict = cross_val_predict(modelo_rf,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, RF_Predict).ravel() \n",
        "R_Forest = fp / (fp + tn)\n",
        "\n",
        "XG_Predict = cross_val_predict(modelo_xgboost,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, XG_Predict).ravel()\n",
        "XG_BOOST = fp / (fp + tn)\n",
        "\n",
        "LGBM_Predict = cross_val_predict(modelo_lgbm,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, LGBM_Predict).ravel()\n",
        "Light_GBM = fp / (fp + tn)\n",
        "\n",
        "\n",
        "# Criando lista com fp \n",
        "lista_fp = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "menor_fp = min(lista_fp)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "cores = ['blue'] * len(lista_fp)\n",
        "indice_menor_fp = lista_fp.index(menor_fp)\n",
        "cores[indice_menor_fp] = 'red'\n",
        "\n",
        "# Criando rótulos para as barras com o valor FP e o percentual correspondente\n",
        "labels = [f'{fp_perc:.2%}' for nome, fp, fp_perc in zip(nome_algoritmos, lista_fp,(lista_fp)*100 )]\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=lista_fp, marker=dict(color=cores), text=labels, textposition='auto')]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de Falsos Positivos entre os Algoritmos',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='Falsos Positivos'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H2ORVdhUu4rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'>Falsos Negativos</font> - Erro Tipo II"
      ],
      "metadata": {
        "id": "vD9pxqEZU0zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Avalie Falsos Negativos dos Algoritmos\n",
        "#@markdown > * Falsos negativos ocorrem em avaliações de classificadores quando uma amostra é erroneamente classificada como negativa quando, na verdade, ela deveria ter sido classificada como positiva. Em outras palavras, o classificador falha em detectar uma condição ou evento que deveria ser considerado positivo, gerando um Erro do Tipo II.\n",
        "\n",
        "#@markdown > Por exemplo, em um teste de detecção de câncer, um falso negativo ocorre quando um paciente que realmente tem câncer é diagnosticado como não tendo a doença. Isso pode levar a um atraso no tratamento ou até mesmo à morte.\n",
        "\n",
        "#@markdown #### IMPORTANTE: considere o algoritmo com menor taxa de Falsos Negativos.\n",
        "\n",
        "# Importando biblioteca:\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# Validando o fn\n",
        "N_Bayes_Predict = cross_val_predict(modelo_nbayes,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, N_Bayes_Predict).ravel()\n",
        "Naive_Bayes = fn / (fn + tp)\n",
        "\n",
        "SVM_Predict = cross_val_predict(modelo_svm,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, SVM_Predict).ravel()\n",
        "S_V_M = fn / (fn + tp)\n",
        "\n",
        "RL_Predict = cross_val_predict(modelo_rl,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, RL_Predict).ravel()\n",
        "Reg_Logistica = fn / (fn + tp)\n",
        "\n",
        "KNN_Predict = cross_val_predict(modelo_knn,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, KNN_Predict).ravel()\n",
        "K_N_N = fn / (fn + tp)\n",
        "\n",
        "AD_Predict = cross_val_predict(modelo_ad,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, AD_Predict).ravel()\n",
        "Arv_Decisao = fn / (fn + tp)\n",
        "\n",
        "RF_Predict = cross_val_predict(modelo_rf,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, RF_Predict).ravel() \n",
        "R_Forest = fn / (fn + tp)\n",
        "\n",
        "XG_Predict = cross_val_predict(modelo_xgboost,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, XG_Predict).ravel()\n",
        "XG_BOOST = fn / (fn + tp)\n",
        "\n",
        "LGBM_Predict = cross_val_predict(modelo_lgbm,previsores_esc,alvo,cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(alvo, LGBM_Predict).ravel()\n",
        "Light_GBM = fn / (fn + tp)\n",
        "\n",
        "\n",
        "# Criando lista com fn \n",
        "lista_fn = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "menor_fn = min(lista_fn)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "cores = ['blue'] * len(lista_fn)\n",
        "indice_menor_fn = lista_fn.index(menor_fn)\n",
        "cores[indice_menor_fn] = 'red'\n",
        "\n",
        "# Criando rótulos para as barras com o valor fn e o percentual correspondente\n",
        "labels = [f'{fn_perc:.2%}' for nome, fn, fn_perc in zip(nome_algoritmos, lista_fn,(lista_fn)*100 )]\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=lista_fn, marker=dict(color=cores), text=labels, textposition='auto')]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de Falsos Negativos entre os Algoritmos',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='Falsos Negativos'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hcUApmYBU08G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}