{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RVrCAQGjg8_rEMiTzwpovgosBDN6NPCv",
      "authorship_tag": "ABX9TyMsQmGwgSEAMoryEuPpK/IB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauricionoronha/ml_classificacao_simplificada/blob/main/ml_classificacao_simplificada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 1 : Pré-processamento dos dados:</font>\n",
        "\n",
        "* É o processo de limpar, transformar e preparar os dados brutos antes de serem alimentados para um modelo de aprendizado de máquina. \n",
        "\n",
        "* É uma etapa crucial em qualquer projeto de machine learning, pois a qualidade dos dados usados para treinar um modelo tem um grande impacto no desempenho e na precisão do modelo.\n",
        "\n",
        ">Considerada a etapa mais demorada e trabalhosa, mas neste projeto será otimizado em 10 passos. Basta preencher as informações necessárias e rodar a célula.\n"
      ],
      "metadata": {
        "id": "9egPmqojeq0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 1/10 - Carregando a base de dados:</font>"
      ],
      "metadata": {
        "id": "xyE9aoVFTMHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yvd3YeQPXbRJ"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print('\u001b[1;32mCarregando dados...')\n",
        "# Criação dos campos de preenchimento usando #@param\n",
        "#@markdown > ### Insira o endereço do arquivo abaixo e escolha o tipo correto de arquivo que deseja importar:\n",
        "endereco = \"/content/drive/MyDrive/MACHINE_LEARNNING/telecom_users.xlsx\" #@param {type:\"string\"}\n",
        "tipo_arquivo = \"excel\" #@param [\"csv\", \"excel\"]\n",
        "separador = \";\" #@param [\",\", \";\"]\n",
        "\n",
        "if tipo_arquivo == \"csv\":\n",
        "    dados = pd.read_csv( endereco, sep = separador)\n",
        "else:\n",
        "    dados = pd.read_excel(endereco)\n",
        "\n",
        "print('\u001b[1;32mPronto, verifique as 5 primeiras linhas do dataframe:')\n",
        "dados.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 2/10 - Analisando atributos ( variáveis )</font>"
      ],
      "metadata": {
        "id": "BaOitZZTTmsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown  ### Análise quantitativa em % e visualização gráfica por meio de um histograma.\n",
        "#@markdown \n",
        "#@markdown > Informe o nome do atributo que deseja analisar:\n",
        "import plotly.express as px\n",
        "Nome_Atributo = \"Genero\" #@param {type:\"string\"}\n",
        "\n",
        "print('\u001b[1;32mCriando gráfico...')\n",
        "print(display(dados[Nome_Atributo].value_counts(normalize=True).map(\"{:.1%}\".format)));\n",
        "\n",
        "hist1 =  px.histogram (dados,  x = Nome_Atributo, nbins=60) \n",
        "hist1.update_layout(width=800,height=500,title_text='Distribuição {}'.format(Nome_Atributo)) \n",
        "hist1.show()\n",
        "\n",
        "dados2 = dados.copy()\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xD2rHyH9r68a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 3/10 - Verificando e corrigindo valores nulos ( NAN )</font>"
      ],
      "metadata": {
        "id": "NDCTSjhgT_Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "print('\u001b[1;32mVerificando dados...')\n",
        "#@markdown > ### Rode essa célula para identificar valores nulos\n",
        "print('\\033[0m' + str(dados2.isnull().sum()))\n",
        "print('\\033[1;32mPronto')"
      ],
      "metadata": {
        "id": "u4HyanG9xU3q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Se encontado valores nulos, como proceder?\n",
        "\n",
        "#@markdown 1 - Excluir Dados Nulos\n",
        "\n",
        "#@markdown 2 - Substituir Dados Nulos Pela Média\n",
        "\n",
        "Escolha = 1 #@param [\"1\", \"2\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown > ###  Informe o nome do Atributo com dados nulos:\n",
        "\n",
        "Nome_Atrib_Dados_Nulos = \"Dependentes\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if Escolha == 1:\n",
        "    dados2.dropna(inplace=True)\n",
        "else:\n",
        "    dados2[Nome_Atrib_Dados_Nulos].fillna(dados2[Nome_Atrib_Dados_Nulos].mean(), inplace=True)\n",
        "\n",
        "print('\u001b[1;32mDados corrigidos!')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zfn3RNBhx8GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'>  4/10 - Analisando os tipos de atributos</font>"
      ],
      "metadata": {
        "id": "qhFw2eu8UL2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown  ### Verifique os tipos de atributos, que podem ser:\n",
        "#@markdown * object: strings\n",
        "#@markdown * int64: inteiros\n",
        "#@markdown * float64: reais\n",
        "#@markdown * complex: complexos\n",
        "print('\u001b[1;32mAnalisando dados...')\n",
        "print('\\033[0m' + str(dados2.dtypes))\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5P83WgrUTbhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Será necessário alterar o tipo de um atributo especifico?\n",
        "\n",
        "#@markdown * Desconsidere se não for necessário corrigir o tipo do atributo\n",
        "print('\u001b[1;32mCorrigindo dados...')\n",
        "#@markdown > Se for necessário fazer a correção, informe o nome do atributo:\n",
        "Nome_Atributo = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Escolha agora, entre as opções abaixo, para qual tipo deseja alterar:\n",
        "Tipo_Atributo = \"float64\" #@param [\"object\", \"int64\", \"float64\"]\n",
        "\n",
        "if Tipo_Atributo == \"object\":\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].astype(str)\n",
        "elif Tipo_Atributo == \"int64\":\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].apply(np.int64)\n",
        "else:\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].apply(np.float64)\n",
        "\n",
        "print(dados2[Nome_Atributo].dtype)\n",
        "\n",
        "#@markdown * OBS.: Só é possivel converter uma STRING (object) em INT ou FLOAT quando essa string é composta apenas por números, logo não é possivel converter palavras em int ou float\n",
        "print('\u001b[1;32mPronto')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TgB94TvCU9ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 5/10 - Excluindo atributos desnecessários</font>"
      ],
      "metadata": {
        "id": "-eqwHOX7UYNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Informe o nome do atributo que deseja retirar do dataframe:\n",
        "Nome_Atributo = \"ValorBackupOnline\" #@param {type:\"string\"}\n",
        "dados2 = dados2.drop(Nome_Atributo, axis=1)\n",
        "print('\\033[1;32mAtributo excluído!')\n",
        "print('\\033[1;32mSegue amostra do dataframe atualizado:')\n",
        "dados2.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z-GPY4L3vgqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 6/10 - Relação quantitativa entre todos os atributos e um atributo chave:</font>"
      ],
      "metadata": {
        "id": "PfgY51n4UqNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### Veja através de histograma como o atributo chave é distribuído nos demais atributos do dataframe.\n",
        "print('\u001b[1;32mCriando gráficos...')\n",
        "#@markdown > Informe o nome do atributo chave: \n",
        "import plotly.express as px\n",
        "\n",
        "Atributo_Chave = \"Churn\" #@param{type: 'string'}\n",
        "\n",
        "for coluna in dados2:      \n",
        "        fig = px.histogram(dados2, x=coluna,nbins=60, color=Atributo_Chave)\n",
        "        fig.show()\n",
        "\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PBSyUs3cv394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 7/10 - Análise Estatística Descritiva</font>"
      ],
      "metadata": {
        "id": "qynKFN-CUzLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "\n",
        "#@markdown > ### Tenha acesso aos seguintes perâmetros :\n",
        "\n",
        "#@markdown * count: número de valores não nulos na coluna\n",
        "#@markdown * mean: média dos valores na coluna\n",
        "#@markdown * std: desvio padrão dos valores na coluna\n",
        "#@markdown * 25%: primeiro quartil (valor abaixo do qual estão 25% dos valores)\n",
        "#@markdown * 50%: segundo quartil, que é equivalente à mediana (valor abaixo do qual estão 50% dos valores)\n",
        "#@markdown * 75%: terceiro quartil (valor abaixo do qual estão 75% dos valores)\n",
        "#@markdown * max: valor máximo na coluna\n",
        "print('\u001b[1;32mAnalisando dados...')\n",
        "dados2.describe()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8RvSVg1zl3bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 8/10 - Verificando correlação entre variáveis</font>"
      ],
      "metadata": {
        "id": "NqrTozV7VAQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Rode a célula para verificar em um quadro com gráficos de dispersão se existe alguma correlação entre variáveis\n",
        "print('\u001b[1;32mProcessando dados...')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.pairplot(dados2);\n",
        "\n",
        "print('\u001b[1;32mCriando gráficos...')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h-mKI5CzSVfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 9/10 - Verificando Outliers</font>"
      ],
      "metadata": {
        "id": "rwl8NLRgVIi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Informe o nome do atributo para criar um gráfico Boxplot e identificar possíveis outliers ( discrepâncias ):\n",
        "print('\u001b[1;32mCriando gráfico...')\n",
        "Nome_Atributo = \"ValorMensal\" #@param {type:\"string\"}\n",
        "\n",
        "import plotly.express as px\n",
        "px.box ( dados2, y = Nome_Atributo)\n",
        "\n",
        "#@markdown * Apropriado para atributos categóricos ordinais ( que tenham valores numéricos )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HDeB4Kl2BL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Corrigindo outliers\n",
        "#@markdown ---\n",
        "#@markdown > ###  Informe o atributo para correção:\n",
        "Nome_Atributo = \"ValorTelefone\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown >###  Informe como tratar outliers:\n",
        "#@markdown * 1 - Exclua valores discrepantes baseados um uma condição\n",
        "#@markdown * 2 - Substitua valores discrepantes pela média baseado em uma condição\n",
        "#@markdown * 3 - Substitua valores discrepantes por um valor específico baseado em uma condição\n",
        "Tipo_correcao = \"2\" #@param [\"1\", \"2\", \"3\"]\n",
        "\n",
        "#@markdown > ###  Informe agora qual a condição:\n",
        "#@markdown Corrija todos os valores que sejam:\n",
        "Tipo_condicao = \"maior_que\" #@param [\"igual_a\", \"maior_que\", \"menor_que\", \"diferente_de\"]\n",
        "Valor = 200 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown > Se escolheu a opção 3 para substituir os valores discrepantes por um valor específico, informe o valor para qual deseja substituir:\n",
        "Valor_substituição = 0 #@param {type:\"number\"}\n",
        "\n",
        "if Tipo_correcao == 1:\n",
        "    # excluir os dados de um atributo baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] == Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] > Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] < Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] != Valor].index, inplace = True)\n",
        "elif Tipo_correcao == 2:\n",
        "    # substituir os dados de um atributo pela média baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2.loc[dados2[Nome_Atributo] == Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] > Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] < Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2.loc[dados2[Nome_Atributo] != Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "else:\n",
        "    # substituir os dados de um atributo por um valor específico baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2.loc[dados2[Nome_Atributo] == Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] > Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] < Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2.loc[dados2[Nome_Atributo] != Valor, Nome_Atributo] = Valor_substituição\n",
        "\n",
        "print('\u001b[1;32mDados corrigidos!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ovR0rA4CF6Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 10/10 - Transformando variáveis categóricas NOMINAIS em variáveis categóricas ORDINAIS</font>"
      ],
      "metadata": {
        "id": "rc94WNaSVTdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### É extremamente importante assegurar que não existam dados nominais (string) no dataframe, pois os modelos de machine learning usados entendem apenas dados numéricos (int ou float)\n",
        "\n",
        "#@markdown * Essa tranformação ocorre do seguinte modo:\n",
        "\n",
        "#@markdown * Considere um atributo Sexo com 2 opções: Masculino e Feminino. \n",
        "\n",
        "#@markdown * Realizando a transformação, os dados nominais \"Masculino\" e \"Feminino\" serão substituídos por dados ordinais 0 e 1. \n",
        "\n",
        "#@markdown  > ###  >>> Rode a célula para realizar os ajustes <<<\n",
        "\n",
        "# Armazenando os indices das variaveis nominais para uso posterior ( onehotencoder )\n",
        "indice_nominal = [dados2.columns.get_loc(col) for col in dados2.select_dtypes(include=[object]).columns]\n",
        "\n",
        "# Importação da biblioteca para transformar as variáveis\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Criando uma lista com todos os atributos nominais\n",
        "nominais = [i for i, dtype in enumerate(dados2.dtypes) if dtype == object]\n",
        "\n",
        "# Usando LabelEncoder para transformar todos atributos nominais lista em ordinais \n",
        "for i in nominais:\n",
        "    dados2.iloc[:, i] = LabelEncoder().fit_transform(dados2.iloc[:, i])\n",
        "\n",
        "print('\u001b[1;32mDados alterados!')\n",
        "print('\\033[1;32mSegue amostra do dataframe atualizado:')\n",
        "dados2.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Uihn4CWJiJrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFFF00'>Salvando e Carregando a base de dados pré-processada</font>"
      ],
      "metadata": {
        "id": "cY96PyqMpRGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### Opcionalmente é possivel salvar o dataframe tratado como um arquivo csv para consultas posteriores e também é possível carregar um dataframe salvo \n",
        "\n",
        "#@markdown >  Se deseja salvar o dataframe tratado, marque a caixa abaixo e informe o nome do arquivo:\n",
        "Salvar = True #@param {type:\"boolean\"}\n",
        "Nome_arquivo = \"churn_TRATADO\" #@param {type:\"string\"}\n",
        "Nome_arquivo_csv = Nome_arquivo + \".csv\"\n",
        "if not Salvar:\n",
        "  print(\"\")\n",
        "else:\n",
        "  dados2.to_csv(Nome_arquivo_csv,sep = \",\", encoding = \"utf-8\",  index = False)\n",
        "  print('\u001b[1;32mDados Salvos!')\n",
        "\n",
        "#@markdown >  Se deseja carregar um dataframe tratado, marque a caixa abaixo e informe o endereço do arquivo e o separador:\n",
        "Carregar = False #@param {type:\"boolean\"}\n",
        "endereco = \"\" #@param {type:\"string\"}\n",
        "separador = \";\" #@param [\",\", \";\"]\n",
        "\n",
        "if not Carregar:\n",
        "    print(\"\")\n",
        "else:\n",
        "    dados2 = pd.read_csv( endereco, sep = separador, encoding = \"utf-8\")\n",
        "    print('\u001b[1;32mPronto, verifique as 5 primeiras linhas do dataframe:')\n",
        "    dados.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "yZyQie9cqDjV",
        "outputId": "8dd162df-e0a9-477a-9906-b4e2c1636b75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDados Salvos!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'>  ETAPA 2: Otimização dos dados para a criação do modelo</font>"
      ],
      "metadata": {
        "id": "Vxl0YBa3fRBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Divisão de Previsores e Alvo </font>\n",
        "#@markdown ---\n",
        "#@markdown * Atributos Previsores - (também conhecidos como \"features\" ou \"variáveis independentes\") são as características ou variáveis de entrada que são utilizadas para prever o valor de uma variável de saída. Em outras palavras, os atributos previsores são as informações que alimentam um modelo de machine learning, com o objetivo de produzir uma previsão ou classificação.\n",
        "#@markdown * Atributo Alvo (também conhecido como \"variável dependente\" ou \"rótulo\") é a variável de saída que o modelo de machine learning está tentando prever ou classificar com base nos atributos previsores.\n",
        "\n",
        "#@markdown > ### Informe o Atributo Alvo do dataframe:\n",
        "Nome_Atributo = \"Churn\" #@param {type:\"string\"}\n",
        "# o complemento .values retorna uma matriz com os dados do dataframe\n",
        "# Divisão previsores e alvo\n",
        "previsores = dados2.drop(Nome_Atributo, axis=1).values\n",
        "alvo = dados2[[Nome_Atributo]].values\n",
        "\n",
        "# Excluindo o atributo Alvo da lista de indice_nominal\n",
        "indice_alvo = dados2.columns.get_loc(Nome_Atributo)\n",
        "indice_nominal.remove(indice_alvo)\n",
        "print('\u001b[1;32mPrevisores e Alvo criados!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "T_UzrRVdpyqe",
        "outputId": "dd352719-7fca-420c-874c-c977f2a69c46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mPrevisores e Alvo criados!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Escalonamento de variáveis </font>\n",
        "#@markdown ---\n",
        "#@markdown * O objetivo do escalonamento de variáveis é normalizar as variáveis para que elas tenham a mesma escala e variem em uma faixa semelhante.\n",
        "\n",
        "#@markdown * Isso é necessário porque muitos algoritmos de Machine Learning são sensíveis à escala das variáveis. Se as variáveis tiverem escalas muito diferentes, isso pode levar a problemas como o algoritmo atribuir maior importância a variáveis com escalas maiores e menor importância a variáveis com escalas menores. Além disso, pode afetar a convergência dos algoritmos.\n",
        "\n",
        "#@markdown  > ###  >>> Rode a célula para realizar os ajustes <<<\n",
        "\n",
        "# Importanto as bibliotecas necessárias:\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "previsores_one = ColumnTransformer(transformers = [(\"OneHot\", OneHotEncoder(), indice_nominal)],\n",
        "                                       remainder = \"passthrough\").fit_transform(previsores)\n",
        "\n",
        "previsores_esc = StandardScaler().fit_transform(previsores_one)                                       \n",
        "print('\u001b[1;32mEscalonamento efetuado!')\n",
        "print('\u001b[1;32mSegue os dados escalonados:')\n",
        "previsores_esc\n"
      ],
      "metadata": {
        "id": "ocSXBXxBzmBl",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3b40f2-c620-4e05-d79c-efc650579c17"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mEscalonamento efetuado!\n",
            "\u001b[1;32mSegue os dados escalonados:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.01923578, -1.01923578, -1.5306916 , ..., -0.65455138,\n",
              "        -0.31864502, -0.39402955],\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.65455138,\n",
              "        -0.31864502, -0.59847607],\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.65455138,\n",
              "         0.01691246, -0.49522716],\n",
              "       ...,\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.80079527,\n",
              "         0.20865958, -0.29078064],\n",
              "       [-0.98112726,  0.98112726,  0.65329946, ..., -0.80079527,\n",
              "        -0.31864502, -0.7352296 ],\n",
              "       [-0.98112726,  0.98112726, -1.5306916 , ..., -0.80079527,\n",
              "        -0.31864502, -0.59915984]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  ## <font color='#FFA500'> Separando base de treino e teste </font>\n",
        "#@markdown ---\n",
        "#@markdown * Informe o tamanho em porcentagem dos dados de teste. O restante será separado automaticamente para dos dados de treino. \n",
        "\n",
        "1#@markdown > O tamanho padrão de dados de teste é de 30% mas você pode escolher outros tamanhos conforme a necessidade: \n",
        "Tamanho_Base_Teste = \"30% - PADRAO\" #@param [\"10%\", \"15%\", \"20%\", \"25%\", \"30% - PADRAO\", \"35%\", \"40%\", \"45%\", \"50%\"]\n",
        "if Tamanho_Base_Teste == \"20%\":\n",
        "    Tamanho_Teste = 0.2\n",
        "elif Tamanho_Base_Teste == \"25%\":\n",
        "    Tamanho_Teste = 0.25\n",
        "elif Tamanho_Base_Teste == \"30% - PADRAO\":\n",
        "    Tamanho_Teste = 0.3\n",
        "elif Tamanho_Base_Teste == \"35%\":\n",
        "    Tamanho_Teste = 0.35\n",
        "elif Tamanho_Base_Teste == \"40%\":\n",
        "    Tamanho_Teste = 0.4\n",
        "elif Tamanho_Base_Teste == \"45%\":\n",
        "    Tamanho_Teste = 0.45\n",
        "elif Tamanho_Base_Teste == \"50%\":\n",
        "    Tamanho_Teste = 0.5\n",
        "else:\n",
        "    print(\"Valor inválido para Tamanho_Base_Teste\")\n",
        "\n",
        "# Importação de biblioteca \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divisão de dados de treino e teste:\n",
        "x_treino,x_teste,y_treino,y_teste = train_test_split(previsores_esc, alvo, test_size=Tamanho_Teste, random_state=0)\n",
        "\n",
        "print('\\033[1;32mDivisão efetuada!')\n",
        "print('\\033[1;32mTamanho base de treino (linhas, colunas):')\n",
        "print('\\033[0m'+ str(x_treino.shape))\n",
        "print('\\033[1;32mTamanho base de teste (linhas, colunas):')\n",
        "print('\\033[0m'+ str(x_teste.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "vXdBzhEKuYBG",
        "outputId": "49e788d1-7fa1-4e18-d3af-fc971f076fee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDivisão efetuada!\n",
            "\u001b[1;32mTamanho base de treino (linhas, colunas):\n",
            "\u001b[0m(4188, 43)\n",
            "\u001b[1;32mTamanho base de teste (linhas, colunas):\n",
            "\u001b[0m(1796, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 3: Aplicação dos algoritmos de Machine Leaning</font>"
      ],
      "metadata": {
        "id": "5u4A3faaHvTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste projeto será utilizado os principais algoritmos de classificação para aprendizado supervisionado, sendo eles:\n",
        "* Naive Bayes\n",
        "* SVM (Máquina de Vetor de Suporte)\n",
        "* Regressão Logística\n",
        "* KNN (K Vizinhos Próximos)\n",
        "* Árvore de Decisão\n",
        "* Random Forest\n",
        "* XGBoost\n",
        "* Light GBM\n",
        "* CATBoost\n",
        "\n",
        "Alguns algoritmos disponibilizam configuração de hiperparâmetros para otimização de resultados. \n",
        "\n",
        "> ## ATENÇÃO!!! \n",
        "É possível rodar todos os algoritmos de uma única vez minimizando as células seguintes com a seta ao lado.\n",
        "Todos os hiperparâmetros já estão estão configurados como default.\n"
      ],
      "metadata": {
        "id": "Rb3QICitIAJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Naive Bayes</font>"
      ],
      "metadata": {
        "id": "Co1JeykiQqmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown Naive Bayes é um método probabilístico utilizado para classificar dados em categorias. Ele utiliza o Teorema de Bayes para calcular a probabilidade de um dado pertencer a uma determinada categoria com base nas probabilidades condicionais dos atributos que o caracterizam.\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "print('\\033[1;32mProcessando Naive Bayes...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "\n",
        "# Importando as biliotecas:\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Treinando o algoritmo:\n",
        "naive = GaussianNB()\n",
        "naive.fit(x_treino,y_treino)\n",
        "\n",
        "# Usando base de teste\n",
        "previsoes_naive = naive.predict(x_teste)\n",
        "\n",
        "# Usando base de treino\n",
        "previsoes_treino = naive.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ str(accuracy_score(y_teste, previsoes_naive)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ str(accuracy_score(y_treino,previsoes_treino)))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_naive)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_naive)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Importando as bibliotecas para Validação Cruzada\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = GaussianNB()\n",
        "resultado = cross_val_score(modelo,previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mNaive Bayes finalizado!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "biA8zoGnYCBL",
        "outputId": "f2734a8b-4efc-44e2-9210-4a6d1e3afc3f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mProcessando Naive Bayes...\n",
            "\u001b[0m=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Teste:\n",
            "\u001b[0m0.6826280623608018\n",
            "\n",
            "\u001b[1;32mAcurácia da Base de Treino:\n",
            "\u001b[0m0.6914995224450812\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Teste:\n",
            "\u001b[0m[[842 498]\n",
            " [ 72 384]]\n",
            "\n",
            "\u001b[1;32mMatriz de Confusão da Base de Treino:\n",
            "\u001b[0m[[1924 1133]\n",
            " [ 159  972]]\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Teste:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.63      0.75      1340\n",
            "           1       0.44      0.84      0.57       456\n",
            "\n",
            "    accuracy                           0.68      1796\n",
            "   macro avg       0.68      0.74      0.66      1796\n",
            "weighted avg       0.80      0.68      0.70      1796\n",
            "\n",
            "\u001b[1;32mRelatório de Classificação da Base de Treino:\n",
            "\u001b[0m              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.63      0.75      3057\n",
            "           1       0.46      0.86      0.60      1131\n",
            "\n",
            "    accuracy                           0.69      4188\n",
            "   macro avg       0.69      0.74      0.67      4188\n",
            "weighted avg       0.80      0.69      0.71      4188\n",
            "\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mAcurácia na Validação Cruzada:\n",
            "\u001b[0mAcurácia Média: 68.90%\n",
            "\n",
            "=======================================================\n",
            "\n",
            "\u001b[1;32mNaive Bayes finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> SVM - Máquina de Vetor de Suporte</font>"
      ],
      "metadata": {
        "id": "1emnwJoh70lS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JiCmimO7xmy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}