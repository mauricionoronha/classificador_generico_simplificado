{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Co1JeykiQqmT",
        "1emnwJoh70lS",
        "4GMvfo4rl9yv",
        "O2u6qMQhzfdK",
        "PYbxHBVXj0AN",
        "9SBBVBHD8XxH"
      ],
      "mount_file_id": "1RVrCAQGjg8_rEMiTzwpovgosBDN6NPCv",
      "authorship_tag": "ABX9TyMwnePfwvSxCfJ+Z950ZkMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauricionoronha/ml_classificacao_simplificada/blob/main/ml_classificacao_simplificada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 1 : Pré-processamento dos dados:</font>\n",
        "\n",
        "* É o processo de limpar, transformar e preparar os dados brutos antes de serem alimentados para um modelo de aprendizado de máquina. \n",
        "\n",
        "* É uma etapa crucial em qualquer projeto de machine learning, pois a qualidade dos dados usados para treinar um modelo tem um grande impacto no desempenho e na precisão do modelo.\n",
        "\n",
        ">Considerada a etapa mais demorada e trabalhosa, mas neste projeto será otimizado em 10 passos. Basta preencher as informações necessárias e rodar a célula.\n"
      ],
      "metadata": {
        "id": "9egPmqojeq0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 1/10 - Carregando a base de dados:</font>"
      ],
      "metadata": {
        "id": "xyE9aoVFTMHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yvd3YeQPXbRJ"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print('\u001b[1;32mCarregando dados...')\n",
        "# Criação dos campos de preenchimento usando #@param\n",
        "#@markdown > ### Insira o endereço do arquivo abaixo e escolha o tipo correto de arquivo que deseja importar:\n",
        "endereco = \"/content/drive/MyDrive/MACHINE_LEARNNING/telecom_users.xlsx\" #@param {type:\"string\"}\n",
        "tipo_arquivo = \"excel\" #@param [\"csv\", \"excel\"]\n",
        "separador = \";\" #@param [\",\", \";\"]\n",
        "\n",
        "if tipo_arquivo == \"csv\":\n",
        "    dados = pd.read_csv( endereco, sep = separador)\n",
        "else:\n",
        "    dados = pd.read_excel(endereco)\n",
        "\n",
        "print('\u001b[1;32mPronto, verifique as 5 primeiras linhas do dataframe:')\n",
        "dados.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 2/10 - Analisando atributos ( variáveis )</font>"
      ],
      "metadata": {
        "id": "BaOitZZTTmsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown  ### Análise quantitativa em % e visualização gráfica por meio de um histograma.\n",
        "#@markdown \n",
        "#@markdown > Informe o nome do atributo que deseja analisar:\n",
        "import plotly.express as px\n",
        "Nome_Atributo = \"Churn\" #@param {type:\"string\"}\n",
        "\n",
        "print('\u001b[1;32mCriando gráfico...')\n",
        "print(display(dados[Nome_Atributo].value_counts(normalize=True).map(\"{:.1%}\".format)));\n",
        "\n",
        "hist1 =  px.histogram (dados,  x = Nome_Atributo, nbins=60) \n",
        "hist1.update_layout(width=800,height=500,title_text='Distribuição {}'.format(Nome_Atributo)) \n",
        "hist1.show()\n",
        "\n",
        "dados2 = dados.copy()\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xD2rHyH9r68a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 3/10 - Verificando e corrigindo valores nulos ( NAN )</font>"
      ],
      "metadata": {
        "id": "NDCTSjhgT_Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "print('\u001b[1;32mVerificando dados...')\n",
        "#@markdown > ### Rode essa célula para identificar valores nulos\n",
        "print('\\033[0m' + str(dados2.isnull().sum()))\n",
        "print('\\033[1;32mPronto')"
      ],
      "metadata": {
        "id": "u4HyanG9xU3q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Se encontado valores nulos, como proceder?\n",
        "\n",
        "#@markdown 1 - Excluir Dados Nulos\n",
        "\n",
        "#@markdown 2 - Substituir Dados Nulos Pela Média\n",
        "\n",
        "Escolha = 1 #@param [\"1\", \"2\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown > ###  Informe o nome do Atributo com dados nulos:\n",
        "\n",
        "Nome_Atrib_Dados_Nulos = \"Churn\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if Escolha == 1:\n",
        "    dados2.dropna(inplace=True)\n",
        "else:\n",
        "    dados2[Nome_Atrib_Dados_Nulos].fillna(dados2[Nome_Atrib_Dados_Nulos].mean(), inplace=True)\n",
        "\n",
        "print('\u001b[1;32mDados corrigidos!')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zfn3RNBhx8GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'>  4/10 - Analisando os tipos de atributos</font>"
      ],
      "metadata": {
        "id": "qhFw2eu8UL2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown  ### Verifique os tipos de atributos, que podem ser:\n",
        "#@markdown * object: strings\n",
        "#@markdown * int64: inteiros\n",
        "#@markdown * float64: reais\n",
        "#@markdown * complex: complexos\n",
        "print('\u001b[1;32mAnalisando dados...')\n",
        "print('\\033[0m' + str(dados2.dtypes))\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5P83WgrUTbhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Será necessário alterar o tipo de um atributo especifico?\n",
        "\n",
        "#@markdown * Desconsidere se não for necessário corrigir o tipo do atributo\n",
        "print('\u001b[1;32mCorrigindo dados...')\n",
        "#@markdown > Se for necessário fazer a correção, informe o nome do atributo:\n",
        "Nome_Atributo = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Escolha agora, entre as opções abaixo, para qual tipo deseja alterar:\n",
        "Tipo_Atributo = \"float64\" #@param [\"object\", \"int64\", \"float64\"]\n",
        "\n",
        "if Tipo_Atributo == \"object\":\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].astype(str)\n",
        "elif Tipo_Atributo == \"int64\":\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].apply(np.int64)\n",
        "else:\n",
        "    dados2[Nome_Atributo] = dados2[Nome_Atributo].apply(np.float64)\n",
        "\n",
        "print(dados2[Nome_Atributo].dtype)\n",
        "\n",
        "#@markdown * OBS.: Só é possivel converter uma STRING (object) em INT ou FLOAT quando essa string é composta apenas por números, logo não é possivel converter palavras em int ou float\n",
        "print('\u001b[1;32mPronto')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TgB94TvCU9ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 5/10 - Excluindo atributos desnecessários</font>"
      ],
      "metadata": {
        "id": "-eqwHOX7UYNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Informe o nome do atributo que deseja retirar do dataframe:\n",
        "Nome_Atributo = \"ValorBackupOnline\" #@param {type:\"string\"}\n",
        "dados2 = dados2.drop(Nome_Atributo, axis=1)\n",
        "print('\\033[1;32mAtributo excluído!')\n",
        "print('\\033[1;32mSegue amostra do dataframe atualizado:')\n",
        "dados2.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z-GPY4L3vgqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 6/10 - Relação quantitativa entre todos os atributos e um atributo chave:</font>"
      ],
      "metadata": {
        "id": "PfgY51n4UqNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### Veja através de histograma como o atributo chave é distribuído nos demais atributos do dataframe.\n",
        "print('\u001b[1;32mCriando gráficos...')\n",
        "#@markdown > Informe o nome do atributo chave: \n",
        "import plotly.express as px\n",
        "\n",
        "Atributo_Chave = \"\" #@param{type: 'string'}\n",
        "\n",
        "for coluna in dados2:      \n",
        "        fig = px.histogram(dados2, x=coluna,nbins=60, color=Atributo_Chave)\n",
        "        fig.show()\n",
        "\n",
        "print('\u001b[1;32mPronto')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PBSyUs3cv394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 7/10 - Análise Estatística Descritiva</font>"
      ],
      "metadata": {
        "id": "qynKFN-CUzLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "\n",
        "#@markdown > ### Tenha acesso aos seguintes perâmetros :\n",
        "\n",
        "#@markdown * count: número de valores não nulos na coluna\n",
        "#@markdown * mean: média dos valores na coluna\n",
        "#@markdown * std: desvio padrão dos valores na coluna\n",
        "#@markdown * 25%: primeiro quartil (valor abaixo do qual estão 25% dos valores)\n",
        "#@markdown * 50%: segundo quartil, que é equivalente à mediana (valor abaixo do qual estão 50% dos valores)\n",
        "#@markdown * 75%: terceiro quartil (valor abaixo do qual estão 75% dos valores)\n",
        "#@markdown * max: valor máximo na coluna\n",
        "print('\u001b[1;32mAnalisando dados...')\n",
        "dados2.describe()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8RvSVg1zl3bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 8/10 - Verificando correlação entre variáveis</font>"
      ],
      "metadata": {
        "id": "NqrTozV7VAQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Rode a célula para verificar em um quadro com gráficos de dispersão se existe alguma correlação entre variáveis\n",
        "print('\u001b[1;32mProcessando dados...')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.pairplot(dados2);\n",
        "\n",
        "print('\u001b[1;32mCriando gráficos...')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h-mKI5CzSVfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 9/10 - Verificando Outliers</font>"
      ],
      "metadata": {
        "id": "rwl8NLRgVIi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown > ### Informe o nome do atributo para criar um gráfico Boxplot e identificar possíveis outliers ( discrepâncias ):\n",
        "print('\u001b[1;32mCriando gráfico...')\n",
        "Nome_Atributo = \"ValorMensal\" #@param {type:\"string\"}\n",
        "\n",
        "import plotly.express as px\n",
        "px.box ( dados2, y = Nome_Atributo)\n",
        "\n",
        "#@markdown * Apropriado para atributos categóricos ordinais ( que tenham valores numéricos )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HDeB4Kl2BL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Corrigindo outliers\n",
        "#@markdown ---\n",
        "#@markdown > ###  Informe o atributo para correção:\n",
        "Nome_Atributo = \"ValorTelefone\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown >###  Informe como tratar outliers:\n",
        "#@markdown * 1 - Exclua valores discrepantes baseados um uma condição\n",
        "#@markdown * 2 - Substitua valores discrepantes pela média baseado em uma condição\n",
        "#@markdown * 3 - Substitua valores discrepantes por um valor específico baseado em uma condição\n",
        "Tipo_correcao = \"2\" #@param [\"1\", \"2\", \"3\"]\n",
        "\n",
        "#@markdown > ###  Informe agora qual a condição:\n",
        "#@markdown Corrija todos os valores que sejam:\n",
        "Tipo_condicao = \"maior_que\" #@param [\"igual_a\", \"maior_que\", \"menor_que\", \"diferente_de\"]\n",
        "Valor = 0 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown > Se escolheu a opção 3 para substituir os valores discrepantes por um valor específico, informe o valor para qual deseja substituir:\n",
        "Valor_substituição = 0 #@param {type:\"number\"}\n",
        "\n",
        "if Tipo_correcao == 1:\n",
        "    # excluir os dados de um atributo baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] == Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] > Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] < Valor].index, inplace = True)\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2 = dados2.drop(dados2[dados2[Nome_Atributo] != Valor].index, inplace = True)\n",
        "elif Tipo_correcao == 2:\n",
        "    # substituir os dados de um atributo pela média baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2.loc[dados2[Nome_Atributo] == Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] > Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] < Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2.loc[dados2[Nome_Atributo] != Valor, Nome_Atributo] = dados2[Nome_Atributo].mean()\n",
        "else:\n",
        "    # substituir os dados de um atributo por um valor específico baseado em uma condição\n",
        "    if Tipo_condicao == \"igual_a\":\n",
        "        dados2.loc[dados2[Nome_Atributo] == Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"maior_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] > Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"menor_que\":\n",
        "        dados2.loc[dados2[Nome_Atributo] < Valor, Nome_Atributo] = Valor_substituição\n",
        "    elif Tipo_condicao == \"diferente_de\":\n",
        "        dados2.loc[dados2[Nome_Atributo] != Valor, Nome_Atributo] = Valor_substituição\n",
        "\n",
        "print('\u001b[1;32mDados corrigidos!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ovR0rA4CF6Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#FFA500'> 10/10 Salvando ou Carregando a base de dados pré-processada</font>"
      ],
      "metadata": {
        "id": "cY96PyqMpRGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown * ### Opcionalmente é possivel salvar o dataframe tratado como um arquivo csv para consultas posteriores e também é possível carregar um dataframe salvo \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#@markdown >  Se deseja salvar o dataframe tratado, marque a caixa abaixo e informe o nome do arquivo:\n",
        "Salvar = False #@param {type:\"boolean\"}\n",
        "Nome_arquivo = \"churn_TRATADO\" #@param {type:\"string\"}\n",
        "Nome_arquivo_csv = Nome_arquivo + \".csv\"\n",
        "\n",
        "if Salvar:\n",
        "  dados2.to_csv(Nome_arquivo_csv,sep = \",\", encoding = \"utf-8\",  index = False)\n",
        "  print('\u001b[1;32mDados Salvos!')\n",
        "\n",
        "#@markdown >  Se deseja carregar um dataframe tratado, marque a caixa abaixo e informe o endereço do arquivo e o separador:\n",
        "Carregar = True #@param {type:\"boolean\"}\n",
        "endereco = \"/content/drive/MyDrive/MACHINE_LEARNNING/churn_TRATADO.csv\" #@param {type:\"string\"}\n",
        "separador = \",\" #@param [\",\", \";\"]\n",
        "\n",
        "if Carregar:\n",
        "    dados2 = pd.read_csv(endereco, sep = separador, encoding = \"utf-8\")\n",
        "    print('\u001b[1;32mPronto, Dataframe carregado!'),\n",
        "    print('\\033[0m' + str(\"\"))\n",
        "    print('\\033[0m' + str(dados2.info()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yZyQie9cqDjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'>  ETAPA 2: Otimização dos dados para a criação do modelo</font>"
      ],
      "metadata": {
        "id": "Vxl0YBa3fRBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Transformando variáveis categóricas NOMINAIS em variáveis categóricas ORDINAIS </font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * ### É extremamente importante assegurar que não existam dados nominais (string) no dataframe, pois os modelos de machine learning usados entendem apenas dados numéricos (int ou float)\n",
        "\n",
        "#@markdown * Essa tranformação ocorre do seguinte modo:\n",
        "\n",
        "#@markdown * Considere um atributo Sexo com 2 opções: Masculino e Feminino. \n",
        "\n",
        "#@markdown * Realizando a transformação, os dados nominais \"Masculino\" e \"Feminino\" serão substituídos por dados ordinais 0 e 1. \n",
        "\n",
        "#@markdown  > ###  >>> Rode a célula para realizar os ajustes <<<\n",
        "\n",
        "# Armazenando os indices das variaveis nominais para uso posterior ( onehotencoder )\n",
        "indice_nominal = [dados2.columns.get_loc(col) for col in dados2.select_dtypes(include=[object]).columns]\n",
        "\n",
        "# Importação da biblioteca para transformar as variáveis\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Criando uma lista com todos os atributos nominais\n",
        "nominais = [i for i, dtype in enumerate(dados2.dtypes) if dtype == object]\n",
        "\n",
        "# Usando LabelEncoder para transformar todos atributos nominais lista em ordinais \n",
        "for i in nominais:\n",
        "    dados2.iloc[:, i] = LabelEncoder().fit_transform(dados2.iloc[:, i])\n",
        "\n",
        "print('\u001b[1;32mDados alterados!')\n",
        "print('\\033[1;32mSegue amostra do dataframe atualizado:')\n",
        "dados2.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Uihn4CWJiJrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Divisão de Previsores e Alvo </font>\n",
        "#@markdown ---\n",
        "#@markdown * Atributos Previsores - (também conhecidos como \"features\" ou \"variáveis independentes\") são as características ou variáveis de entrada que são utilizadas para prever o valor de uma variável de saída. Em outras palavras, os atributos previsores são as informações que alimentam um modelo de machine learning, com o objetivo de produzir uma previsão ou classificação.\n",
        "#@markdown * Atributo Alvo (também conhecido como \"variável dependente\" ou \"rótulo\") é a variável de saída que o modelo de machine learning está tentando prever ou classificar com base nos atributos previsores.\n",
        "\n",
        "#@markdown > ### Informe o Atributo Alvo do dataframe:\n",
        "Nome_Atributo = \"Churn\" #@param {type:\"string\"}\n",
        "# o complemento .values retorna uma matriz com os dados do dataframe\n",
        "# Divisão previsores e alvo\n",
        "previsores = dados2.drop(Nome_Atributo, axis=1).values\n",
        "alvo = dados2[[Nome_Atributo]].values\n",
        "\n",
        "# Excluindo o atributo Alvo da lista de indice_nominal\n",
        "indice_alvo = dados2.columns.get_loc(Nome_Atributo)\n",
        "indice_nominal.remove(indice_alvo)\n",
        "print('\u001b[1;32mPrevisores e Alvo criados!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T_UzrRVdpyqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494c4dc3-0942-4628-e7d9-33b01cbf28b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mPrevisores e Alvo criados!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ## <font color='#FFA500'> Escalonamento de variáveis </font>\n",
        "#@markdown ---\n",
        "#@markdown * O objetivo do escalonamento de variáveis é normalizar as variáveis para que elas tenham a mesma escala e variem em uma faixa semelhante.\n",
        "\n",
        "#@markdown * Isso é necessário porque muitos algoritmos de Machine Learning são sensíveis à escala das variáveis. Se as variáveis tiverem escalas muito diferentes, isso pode levar a problemas como o algoritmo atribuir maior importância a variáveis com escalas maiores e menor importância a variáveis com escalas menores. Além disso, pode afetar a convergência dos algoritmos.\n",
        "\n",
        "#@markdown  > ###  >>> Rode a célula para realizar os ajustes <<<\n",
        "\n",
        "# Importanto as bibliotecas necessárias:\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "previsores_one = ColumnTransformer(transformers = [(\"OneHot\", OneHotEncoder(), indice_nominal)],\n",
        "                                       remainder = \"passthrough\").fit_transform(previsores)\n",
        "\n",
        "previsores_esc = StandardScaler().fit_transform(previsores_one)                                       \n",
        "print('\u001b[1;32mEscalonamento efetuado!')\n",
        "print('\u001b[1;32mSegue os dados escalonados:')\n",
        "previsores_esc\n"
      ],
      "metadata": {
        "id": "ocSXBXxBzmBl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  ## <font color='#FFA500'> Separando base de treino e teste </font>\n",
        "#@markdown ---\n",
        "#@markdown * Informe o tamanho em porcentagem dos dados de teste. O restante será separado automaticamente para dos dados de treino. \n",
        "\n",
        "1#@markdown > O tamanho padrão de dados de teste é de 30% mas você pode escolher outros tamanhos conforme a necessidade: \n",
        "Tamanho_Base_Teste = \"30% - PADRAO\" #@param [\"10%\", \"15%\", \"20%\", \"25%\", \"30% - PADRAO\", \"35%\", \"40%\", \"45%\", \"50%\"]\n",
        "if Tamanho_Base_Teste == \"20%\":\n",
        "    Tamanho_Teste = 0.2\n",
        "elif Tamanho_Base_Teste == \"25%\":\n",
        "    Tamanho_Teste = 0.25\n",
        "elif Tamanho_Base_Teste == \"30% - PADRAO\":\n",
        "    Tamanho_Teste = 0.3\n",
        "elif Tamanho_Base_Teste == \"35%\":\n",
        "    Tamanho_Teste = 0.35\n",
        "elif Tamanho_Base_Teste == \"40%\":\n",
        "    Tamanho_Teste = 0.4\n",
        "elif Tamanho_Base_Teste == \"45%\":\n",
        "    Tamanho_Teste = 0.45\n",
        "elif Tamanho_Base_Teste == \"50%\":\n",
        "    Tamanho_Teste = 0.5\n",
        "else:\n",
        "    print(\"Valor inválido para Tamanho_Base_Teste\")\n",
        "\n",
        "# Importação de biblioteca \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divisão de dados de treino e teste:\n",
        "x_treino,x_teste,y_treino,y_teste = train_test_split(previsores_esc, alvo, test_size=Tamanho_Teste, random_state=0)\n",
        "\n",
        "print('\\033[1;32mDivisão efetuada!')\n",
        "print('\\033[1;32mTamanho base de treino (linhas, colunas):')\n",
        "print('\\033[0m'+ str(x_treino.shape))\n",
        "print('\\033[1;32mTamanho base de teste (linhas, colunas):')\n",
        "print('\\033[0m'+ str(x_teste.shape))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vXdBzhEKuYBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 3: Aplicação dos algoritmos de Machine Leaning</font>"
      ],
      "metadata": {
        "id": "5u4A3faaHvTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste projeto será utilizado os principais algoritmos de classificação para aprendizado supervisionado, sendo eles:\n",
        "* Naive Bayes\n",
        "* SVM (Máquina de Vetor de Suporte)\n",
        "* Regressão Logística\n",
        "* KNN (K Vizinhos Próximos)\n",
        "* Árvore de Decisão\n",
        "* Random Forest\n",
        "* XGBoost\n",
        "* Light GBM\n",
        "\n",
        "\n",
        "Alguns algoritmos disponibilizam configuração de hiperparâmetros para otimização de resultados. \n",
        "\n",
        "> ## ATENÇÃO!!! \n",
        "É possível rodar todos os algoritmos de uma única vez minimizando as células seguintes com a seta ao lado.\n",
        "Todos os hiperparâmetros já estão estão configurados como default.\n"
      ],
      "metadata": {
        "id": "Rb3QICitIAJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Naive Bayes</font>"
      ],
      "metadata": {
        "id": "Co1JeykiQqmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown Naive Bayes é um método probabilístico utilizado para classificar dados em categorias. Ele utiliza o Teorema de Bayes para calcular a probabilidade de um dado pertencer a uma determinada categoria com base nas probabilidades condicionais dos atributos que o caracterizam.\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "print('\\033[1;32mProcessando Naive Bayes...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "\n",
        "# Importando as biliotecas:\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Treinando o algoritmo:\n",
        "naive = GaussianNB()\n",
        "naive.fit(x_treino,y_treino)\n",
        "\n",
        "# Usando base de teste\n",
        "previsoes_naive = naive.predict(x_teste)\n",
        "\n",
        "# Usando base de treino\n",
        "previsoes_treino = naive.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_naive)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_naive)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_naive)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Importando as bibliotecas para Validação Cruzada\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = GaussianNB()\n",
        "resultado_nbayes = cross_val_score(modelo,previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_nbayes.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mNaive Bayes finalizado!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "biA8zoGnYCBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> SVM - Máquina de Vetor de Suporte</font>"
      ],
      "metadata": {
        "id": "1emnwJoh70lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown O SVM (Support Vector Machine)  pode ser usado para problemas de classificação e regressão. O objetivo do SVM é encontrar um hiperplano que separe os dados em diferentes classes, maximizando a margem entre os pontos mais próximos de cada classe.\n",
        "\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown > * C: Parâmetro de regularização. Um valor mais alto de C implica em uma classificação mais precisa dos dados de treinamento, mas pode resultar em sobreajuste.\n",
        "#@markdown >\n",
        "#@markdown > #### Informe o valor de C :\n",
        "Valor_C = 60 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "#@markdown >\n",
        "#@markdown > * Kernel: utilizado para mapear os dados de entrada em um espaço de características de maior dimensão. Os kernels comuns são:\n",
        "#@markdown >> * Linear: adequado para problemas de classificação simples onde os dados podem ser linearmente separáveis.\n",
        "#@markdown >> * Polinomial: capaz de separar dados que não são linearmente separáveis, mas pode ser suscetível ao overfitting.\n",
        "#@markdown >> * RBF (Função de Base Radial): capaz de separar dados que não são linearmente separáveis e geralmente produz resultados melhores que o kernel polinomial.\n",
        "#@markdown >> * Sigmoid: adequado para problemas de classificação binária e é especialmente útil para problemas em que os dados têm uma distribuição bimodal.\n",
        "#@markdown >  #### Informe o Kernel:\n",
        "Tipo_Kernel = \"sigmoid\" #@param [\"linear\", \"polynomial\", \"rbf\", \"sigmoid\"]\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando SVM...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando a biblioteca SVM especifico para classificação ( SVC )\n",
        "from sklearn.svm import SVC   \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cria o vetor \"svm\". A configuração kernel para transformar os dados para aplicação da forma correta\n",
        "svm = SVC(kernel=Tipo_Kernel, random_state=1, C= Valor_C) \n",
        "\n",
        "# Criação do fit de treinamento\n",
        "svm.fit(x_treino, y_treino)\n",
        "\n",
        "# Criação do PREVISOR baseado no svm\n",
        "svm_teste =svm.predict(x_teste)\n",
        "\n",
        "# Criação do PREVISOR da base de treino\n",
        "svm_treino = svm.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, svm_teste)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino, svm_treino)*100))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, svm_teste)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, svm_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, svm_teste)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,svm_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "#Criando o modelo\n",
        "modelo=SVC(kernel= Tipo_Kernel,random_state=1,C= Valor_C)\n",
        "resultado_svm= cross_val_score(modelo, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_svm.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mSVM finalizado!')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0JiCmimO7xmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Regressão Logística</font>"
      ],
      "metadata": {
        "id": "4GMvfo4rl9yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown A Regressão Logística é um algoritmo de aprendizado de máquina utilizado para classificação binária, ou seja, para prever se uma observação pertence a uma das duas categorias possíveis (por exemplo, sim ou não, verdadeiro ou falso, etc.).\n",
        "\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Iter:\n",
        "#@markdown  Define o número máximo de iterações para o algoritmo convergir. Este parâmetro controla a quantidade de tempo que o modelo terá para encontrar o melhor conjunto de pesos.\n",
        "#@markdown >\n",
        "#@markdown >  #### Informe o valor de Max_Iter :\n",
        "Valor_Max_Iter = 500 #@param {type:\"slider\", min:20, max:1000, step:20}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Penalty:\n",
        "#@markdown  Define o tipo de regularização que será aplicada ao modelo. A regularização é uma técnica que ajuda a prevenir overfitting, penalizando coeficientes muito grandes. Opções:\n",
        "#@markdown * l1: Adiciona uma penalidade igual à soma dos valores absolutos dos coeficientes. Essa opção pode ser usada para selecionar recursos importantes do modelo, tornando os outros coeficientes iguais a zero.\n",
        "#@markdown * l2: Regularização L2: Adiciona uma penalidade igual à soma dos quadrados dos coeficientes. Essa opção pode ser usada para evitar overfitting, tornando os coeficientes pequenos, mas não necessariamente iguais a zero.\n",
        "#@markdown >  #### Informe o Penalty:\n",
        "Tipo_Penalty = \"l2\" #@param [\"l1\", \"l2\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### C:\n",
        "#@markdown  Define o inverso da força da regularização. Quanto maior o valor de C, menos regularização é aplicada. Este parâmetro pode ser usado para controlar o trade-off entre o viés e a variância do modelo.\n",
        "#@markdown > #### Informe o valor de C:\n",
        "Valor_C = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Solver:\n",
        "#@markdown  Define o algoritmo a ser utilizado no processo de otimização. Opções:\n",
        "#@markdown * newton-cg: É eficiente para dados com muitas amostras e muitas características, mas pode ser lento para conjuntos de dados muito grandes. <font color='#FFFF00'> Somente para Penalty l2 </font>\n",
        "#@markdown * lbfgs: É uma opção mais rápida que o solver \"newton-cg\" e é adequado para conjuntos de dados com muitas amostras e poucas características. <font color='#FFFF00'> Somente para Penalty l2 </font>\n",
        "#@markdown * liblinear: É uma opção mais rápida para conjuntos de dados pequenos e médios, mas pode ter dificuldades para convergir em conjuntos de dados muito grandes.\n",
        "#@markdown * saga: É adequado para conjuntos de dados grandes, mas pode ter dificuldades para convergir em problemas com regularização L1.\n",
        "\n",
        "#@markdown >  #### Informe o Solver:\n",
        "Tipo_Solver = \"lbfgs\" #@param [\"newton-cg\", \"lbfgs\", \"liblinear\", \"saga\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando Regressão Logística...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo\n",
        "logistica = LogisticRegression(random_state=1,max_iter= Valor_Max_Iter, penalty= Tipo_Penalty,tol=0.0001, C= Valor_C, solver= Tipo_Solver)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "logistica.fit(x_treino,y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_logistica = logistica.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino= logistica.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste,previsoes_logistica)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, previsoes_logistica)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, previsoes_logistica)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "#Criando o modelo\n",
        "#Criando o modelo\n",
        "modelo=LogisticRegression(random_state=1,max_iter= Valor_Max_Iter, penalty= Tipo_Penalty,tol=0.0001, C= Valor_C, solver= Tipo_Solver)\n",
        "resultado_rl =cross_val_score(modelo, previsores_esc,alvo, cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_rl.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRegressão Logística finalizada!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7mjxzBR9wXYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> KNN</font>"
      ],
      "metadata": {
        "id": "O2u6qMQhzfdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown O objetivo do KNN é classificar uma amostra desconhecida com base nas classes de exemplos de treinamento mais próximos. Isso é feito calculando a distância entre a amostra desconhecida e todos os exemplos de treinamento no espaço de recursos e selecionando os k exemplos de treinamento mais próximos. A classe mais comum entre esses k exemplos é então atribuída à amostra desconhecida.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### N_Neighbors:\n",
        "#@markdown  é um dos principais parâmetros do algoritmo KNN (K-Nearest Neighbors). Ele controla o número de vizinhos mais próximos que serão considerados para determinar a classe de uma nova amostra. Em outras palavras, o valor de n_neighbors define o tamanho do subconjunto de amostras de treinamento que serão usadas para tomar uma decisão sobre a classe de uma nova amostra.\n",
        "#@markdown >\n",
        "#@markdown >  #### Informe o valor de N_Neighbors :\n",
        "Valor_N_Neighbors = 30 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Metric:\n",
        "#@markdown  Metric controla a métrica de distância que será utilizada para medir a distância entre as amostras do conjunto de treinamento e a nova amostra a ser classificada. Opções:\n",
        "#@markdown * euclidean: mede a distância entre dois pontos em um espaço euclidiano, definida pela raiz quadrada da soma dos quadrados das diferenças entre as coordenadas dos dois pontos.\n",
        "#@markdown * manhattan: mede a distância entre dois pontos ao longo dos eixos, em vez de uma linha reta. A distância Manhattan é definida pela soma das diferenças absolutas entre as coordenadas dos dois pontos.\n",
        "#@markdown * chebyshev: mede a distância máxima ao longo de qualquer dimensão entre dois pontos. É definida como o valor absoluto da diferença máxima entre as coordenadas dos dois pontos.\n",
        "#@markdown * minkowski: é uma métrica de distância geral que inclui a distância Euclidiana e a distância de Manhattan como casos especiais. \n",
        "#@markdown * cosine: calcula a similaridade entre duas amostras, em vez da distância. É útil para dados esparsos e para dados onde a magnitude das características é irrelevante.\n",
        "\n",
        "#@markdown >  #### Informe o Metric:\n",
        "Tipo_Metric = \"cosine\" #@param [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\", \"cosine\"]\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando KNN...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. Se metrics for minkowski recebe um componente adicional p\n",
        "if Tipo_Metric == 'minkowski':\n",
        "    knn = KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric='minkowski',p=2,)\n",
        "else:\n",
        "    knn = KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric=Tipo_Metric)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "knn.fit(x_treino,y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_knn = knn.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino= knn.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_knn)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_knn)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_knn)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "\n",
        "# Criando o modelo. Se metrics for minkowski recebe um componente adicional p\n",
        "if Tipo_Metric == 'minkowski':\n",
        "    modelo= KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric='minkowski',p=2,)\n",
        "else:\n",
        "    modelo= KNeighborsClassifier(n_neighbors=Valor_N_Neighbors, metric=Tipo_Metric)\n",
        "\n",
        "resultado_knn =cross_val_score(modelo, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_knn.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mKNN finalizada!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z8ELCQY_zZGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Árvore de Decisão</font>"
      ],
      "metadata": {
        "id": "PYbxHBVXj0AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Árvore de decisão é um modelo de aprendizado de máquina supervisionado que pode ser usado tanto para tarefas de classificação quanto de regressão. A árvore de decisão divide o conjunto de dados em subconjuntos menores, com base nos valores das variáveis ​​explicativas, para prever a variável de resposta.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Criterion:\n",
        "#@markdown  é usado na árvore de decisão para definir o critério de avaliação da qualidade da divisão em cada nó da árvore. Existem dois critérios populares usados na árvore de decisão:\n",
        "#@markdown * gini: O critério de impureza de Gini mede a probabilidade de classificar incorretamente uma amostra aleatória com base na distribuição das classes naquele nó. Quanto menor o valor da impureza de Gini, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown * entropy: O critério de entropia mede a incerteza da classificação em um determinado nó. Ele é calculado como a soma ponderada do logaritmo da probabilidade de cada classe, multiplicado pela probabilidade negativa. Quanto menor o valor da entropia, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown >  #### Informe o valor de Criterion :\n",
        "Tipo_Criterion = \"entropy\" #@param [\"gini\", \"entropy\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown  hiperparâmetro importante na árvore de decisão que controla a profundidade máxima da árvore. A profundidade de uma árvore de decisão é medida pelo número de ramos que precisamos seguir a partir da raiz para chegar a um nó folha.\n",
        "\n",
        "#@markdown Limitar a profundidade da árvore pode ajudar a evitar o sobreajuste (overfitting) do modelo. Isso significa que, ao limitar a profundidade máxima da árvore, estamos impedindo que a árvore se torne muito complexa e especializada no conjunto de treinamento específico.\n",
        "\n",
        "#@markdown No entanto, definir um valor muito baixo para max_depth pode resultar em subajuste (underfitting), onde o modelo não é complexo o suficiente para capturar padrões importantes no conjunto de dados.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Max_Depth:\n",
        "Valor_Max_Depth = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando Árvore de Decisão...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. \n",
        "arvore = DecisionTreeClassifier(criterion= Tipo_Criterion,random_state=0,max_depth= Valor_Max_Depth)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "arvore.fit(x_treino,y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_arvore = arvore.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino = arvore.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste,previsoes_arvore)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_arvore)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_arvore)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo=DecisionTreeClassifier(criterion= Tipo_Criterion,random_state=0,max_depth= Valor_Max_Depth)\n",
        "\n",
        "resultado_ad =cross_val_score(modelo, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_ad.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mÁrvore de Decisão Finalizada!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "huW-rIEgj0ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> Random Forest</font>\n"
      ],
      "metadata": {
        "id": "hA6z_mhF3hGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown É um algoritmo que combina várias árvores de decisão para fazer previsões. É altamente preciso e pode lidar com conjuntos de dados grandes com características de alta dimensão. Um aspecto importante do algoritmo Random Forest é a sua capacidade de evitar overfitting. \n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### N_Estimators:\n",
        "#@markdown  este é o número de árvores de decisão a serem construídas pelo algoritmo. Valores mais altos podem levar a um modelo mais preciso, mas também aumentam o risco de overfitting.\n",
        "#@markdown >  #### Informe o valor de Max_Depth :\n",
        "Valor_N_Estimators = 500 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Criterion:\n",
        "#@markdown  é usado na árvore de decisão para definir o critério de avaliação da qualidade da divisão em cada nó da árvore. Existem dois critérios populares usados na árvore de decisão:\n",
        "#@markdown * gini: O critério de impureza de Gini mede a probabilidade de classificar incorretamente uma amostra aleatória com base na distribuição das classes naquele nó. Quanto menor o valor da impureza de Gini, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown * entropy: O critério de entropia mede a incerteza da classificação em um determinado nó. Ele é calculado como a soma ponderada do logaritmo da probabilidade de cada classe, multiplicado pela probabilidade negativa. Quanto menor o valor da entropia, mais puro é o nó em termos de distribuição de classe.\n",
        "#@markdown >  #### Informe o valor de Criterion :\n",
        "Tipo_Criterion = \"entropy\" #@param [\"gini\", \"entropy\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown   é a profundidade máxima que cada árvore de decisão pode atingir. Árvores mais profundas podem capturar mais detalhes nos dados, mas também podem levar a overfitting.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Max_Depth:\n",
        "Valor_Max_Depth = 7 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando Random Forest...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. \n",
        "random = RandomForestClassifier(n_estimators= Valor_N_Estimators, criterion= Tipo_Criterion, random_state = 0, max_depth= Valor_Max_Depth)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "random.fit(x_treino, y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_random = random.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino = random.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_random)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino, previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, previsoes_random)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, previsoes_random)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo = RandomForestClassifier(n_estimators= Valor_N_Estimators, criterion= Tipo_Criterion, random_state = 0, max_depth= Valor_Max_Depth)\n",
        "\n",
        "resultado_rf = cross_val_score(modelo, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_rf.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRandom Forest Finalizado!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OZ0v8QXI3gEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> XGBOOST</font>"
      ],
      "metadata": {
        "id": "9SBBVBHD8XxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Algoritmo de aprendizado de máquina baseado em árvores de decisão que foi desenvolvido para melhorar o desempenho do Gradient Boosting. O XGBoost funciona através da criação de um conjunto de árvores de decisão sequenciais, onde cada nova árvore é treinada para corrigir os erros do modelo anterior. Isso é conhecido como boosting, que é um método de aprendizado em que os modelos mais fracos são combinados para criar um modelo mais forte.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown  a profundidade máxima de cada árvore. Valores mais altos podem levar a um modelo mais preciso, mas também aumentam o risco de overfitting.\n",
        "#@markdown >  #### Informe o valor de Max_Depth :\n",
        "Valor_Max_Depth = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Learning_Rate:\n",
        "#@markdown  a taxa de aprendizado do modelo. Valores menores podem levar a uma melhor precisão do modelo, mas também aumentam o tempo de treinamento.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Learning_Rate:\n",
        "Valor_Learning_Rate = 0.5 #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### N_Estimators :\n",
        "#@markdown  especifica o número de árvores de decisão que serão criadas no modelo. Cada árvore é adicionada sequencialmente ao modelo e visa corrigir os erros do modelo anterior. Um valor muito baixo pode resultar em um modelo impreciso, enquanto um valor muito alto pode resultar em overfitting e um modelo que não generaliza bem para novos dados.\n",
        "\n",
        "#@markdown >  #### Informe o valor de N_Estimators:\n",
        "Valor_N_Estimators = 50 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Objective :\n",
        "#@markdown  especifica a função objetivo a ser otimizada durante o treinamento do modelo. A escolha da função objetivo depende do tipo de problema que está sendo abordado, como regressão ou classificação binária/multiclasse. Opções:\n",
        "#@markdown * reg:squarederror: Erro quadrático médio para problemas de regressão.\n",
        "#@markdown * reg:logistic: Função de perda de regressão logística para problemas de classificação binária.\n",
        "#@markdown * binary:logistic:  Função de perda de regressão logística para problemas de classificação binária.\n",
        "#@markdown * multi:softmax: Função de perda de entropia cruzada para problemas de classificação multiclasse.\n",
        "#@markdown * rank:pairwise: Função de perda de classificação para problemas de classificação de ranking.\n",
        "\n",
        "#@markdown >  #### Informe o tipo de Objective:\n",
        "Tipo_Objective = \"reg:logistic\" #@param [\"reg:squarederror\", \"reg:logistic\", \"binary:logistic\", \"multi:softmax\", \"rank:pairwise\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "print('\\033[1;32mProcessando XGBOOST...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "# Importando biblioteca \n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Criando o modelo. \n",
        "xg=XGBClassifier(max_depth= Valor_Max_Depth, learning_rate= Valor_Learning_Rate, n_estimators= Valor_N_Estimators, objective=Tipo_Objective, random_state=3)\n",
        "\n",
        "# Criação do fit de treinamento\n",
        "xg.fit(x_treino, y_treino)\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_xg = xg.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino=xg.predict(x_treino)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste,previsoes_xg)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino,previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste,previsoes_xg)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste,previsoes_xg)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino,previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo=XGBClassifier(max_depth= Valor_Max_Depth, learning_rate= Valor_Learning_Rate, n_estimators= Valor_N_Estimators, objective=Tipo_Objective, random_state=3)\t\t\n",
        "\n",
        "resultado_xgboost = cross_val_score(modelo, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_xgboost.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mXGBOOST Finalizado!')"
      ],
      "metadata": {
        "id": "WZ9pWBfN8YbI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#FFFF00'> LightGBM</font>"
      ],
      "metadata": {
        "id": "YRj2kQHf89pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1;32mProcessando LightGBM...')\n",
        "print('\\033[0m'+ str(55*\"=\"))\n",
        "\n",
        "#@markdown Algoritmo de aprendizado de máquina baseado em árvore que se destaca pela sua eficiência e escalabilidade. Ele usa uma técnica chamada \"histograma de decisão\" para construir as árvores de decisão, o que torna a construção das árvores muito mais rápida do que os algoritmos tradicionais de árvore de decisão.\n",
        "#@markdown ### Hiperparâmetros:\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Num_Boost_Round :\n",
        "#@markdown é um parâmetro no LightGBM, que especifica o número máximo de iterações de treinamento que serão realizadas para ajustar o modelo. Cada iteração adiciona uma nova árvore ao modelo, de modo que aumentar o número de iterações aumenta a complexidade do modelo.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Num_Boost_Round:\n",
        "Valor_Num_Boost_Round = 20 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown ### Max_Depth:\n",
        "#@markdown  este é o limite máximo de profundidade da árvore. Quanto mais profunda a árvore, mais complexa ela será e mais fácil será para o modelo memorizar os dados de treinamento. No entanto, um número muito grande de profundidade pode levar ao overfitting.\n",
        "#@markdown >  #### Informe o valor de Max_Depth :\n",
        "Valor_Max_Depth = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Learning_Rate:\n",
        "#@markdown  a taxa de aprendizado do modelo. Valores menores podem levar a uma melhor precisão do modelo, mas também aumentam o tempo de treinamento.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Learning_Rate:\n",
        "Valor_Learning_Rate = 0.2 #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Num_Leaves :\n",
        "#@markdown  este é o número máximo de folhas permitidas em uma árvore. Quanto maior o número de folhas, mais complexa será a árvore e mais fácil será para o modelo memorizar os dados de treinamento. No entanto, um número muito grande de folhas pode levar ao overfitting.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Num_Leaves:\n",
        "Valor_Num_Leaves = 50 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Max_Bins :\n",
        "#@markdown  este é o número máximo de bins (intervalos) que serão usados para discretizar as variáveis contínuas. A discretização ajuda a lidar com valores extremos e a reduzir o impacto de outliers nos dados. Um número maior de bins pode levar a uma melhor precisão, mas também pode levar a overfitting.\n",
        "\n",
        "#@markdown >  #### Informe o valor de Max_Bins:\n",
        "Valor_Max_Bins = 250 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Objective :\n",
        "#@markdown  é usado para especificar a função de perda que o modelo irá otimizar durante o treinamento. Opções:\n",
        "#@markdown * binary: Usado para problemas de classificação binária. O modelo tenta otimizar a log-verossimilhança binária.\n",
        "#@markdown * multiclass: Usado para problemas de classificação multiclasse. O modelo tenta otimizar a log-verossimilhança softmax.\n",
        "#@markdown * multiclassova:  Usado para problemas de classificação multiclasse. O modelo trata cada classe como um problema de classificação binária e tenta otimizar a log-verossimilhança binária para cada classe.\n",
        "#@markdown * cross_entropy: Usado para problemas de classificação binária ou multiclasse. O modelo tenta minimizar a entropia cruzada entre as distribuições de probabilidade previstas e as distribuições de probabilidade verdadeiras.\n",
        "#@markdown * xentropy: Também usado para problemas de classificação binária ou multiclasse, esta opção é semelhante à cross_entropy`, mas usa uma versão mais eficiente do cálculo da entropia cruzada.\n",
        "\n",
        "#@markdown >  #### Informe o tipo de Objective:\n",
        "Tipo_Objective = \"cross_entropy\" #@param [\"binary\", \"multiclass\", \"multiclassova\", \"cross_entropy\", \"xentropy\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > * Rode a célula para usar o algoritmo. \n",
        "\n",
        "#@markdown > Ao final do processamento você terá acesso aos seguintes resultados:\n",
        "#@markdown    * Acurácia usando base de treino e teste\n",
        "#@markdown    * Matriz de Confusão da base de treino e teste\n",
        "#@markdown    * Relatório de Classificação (precision, recall, f1-score, support)\n",
        "#@markdown    * Acurácia média usando Validação Cruzada\n",
        "\n",
        "\n",
        "# Importando biblioteca \n",
        "import lightgbm as lgb \n",
        "\n",
        "#Evitando a apresentação de mensagens de erro\n",
        "np.warnings.filterwarnings('ignore')\n",
        "\n",
        "# Dataset para treino\n",
        "dataset = lgb.Dataset(x_treino,label=y_treino)\n",
        "\n",
        "# Parâmetros\n",
        "\n",
        "\n",
        "# Criando o modelo. \n",
        "lgbm = lgb.train(\n",
        "    {'num_leaves': Valor_Num_Leaves,\n",
        "     'objective': Tipo_Objective,\n",
        "     'max_depth': Valor_Max_Depth,\n",
        "     'learning_rate': Valor_Learning_Rate,\n",
        "     'max_bin': Valor_Max_Bins\n",
        "    },\n",
        "    dataset,\n",
        "    num_boost_round=Valor_Num_Boost_Round\n",
        ")\n",
        "\n",
        "# Criação do PREVISOR da base de teste\n",
        "previsoes_lgbm = lgbm.predict(x_teste)\n",
        "\n",
        "# Criando Dataframe para receber dados treino\n",
        "previsoes_treino = lgbm.predict(x_treino)\n",
        "\n",
        "# Base de teste: Quando for menor que 5 considera 0 e quando for maior ou igual a 5 considera 1\n",
        "for i in range(0, len(previsoes_lgbm)):\n",
        "    if previsoes_lgbm[i] >= 0.5:       \n",
        "       previsoes_lgbm[i] = 1\n",
        "    else:  \n",
        "       previsoes_lgbm[i] = 0\n",
        "\n",
        "# Base de treino: Quando for menor que 5 considera 0 e quando for maior ou igual a 5 considera 1\n",
        "for i in range(0, len(previsoes_treino)):\n",
        "    if previsoes_treino[i] >= 0.5:       \n",
        "       previsoes_treino[i] = 1\n",
        "    else:  \n",
        "       previsoes_treino[i] = 0\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Teste:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_teste, previsoes_lgbm)*100))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mAcurácia da Base de Treino:')\n",
        "print('\\033[0m'+ \"%0.2f%%\" % (accuracy_score(y_treino, previsoes_treino)*100))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Teste:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_teste, previsoes_lgbm)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mMatriz de Confusão da Base de Treino:')\n",
        "print('\\033[0m'+ str(confusion_matrix(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Teste:')\n",
        "print('\\033[0m'+ str(classification_report(y_teste, previsoes_lgbm)))\n",
        "\n",
        "print('\\033[1;32mRelatório de Classificação da Base de Treino:')\n",
        "print('\\033[0m'+ str(classification_report(y_treino, previsoes_treino)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "# Validação cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# separando os dados em Folds\n",
        "kfold = KFold(n_splits=30, shuffle=True, random_state=5)\n",
        "\n",
        "# Criando o modelo.\n",
        "modelo = lgb.LGBMClassifier(num_leaves = Valor_Num_Leaves, objective = Tipo_Objective,     \n",
        "                            max_depth = Valor_Max_Depth, learning_rate = Valor_Learning_Rate, max_bin =Valor_Max_Bins)\n",
        "\n",
        "resultado_lgbm = cross_val_score(modelo, previsores_esc,alvo,cv=kfold)\n",
        "\n",
        "# Usando a média e desvio padrão\n",
        "print('\\033[1;32mAcurácia na Validação Cruzada:')\n",
        "print('\\033[0m'+ str(\"Acurácia Média: %.2f%%\" %(resultado_lgbm.mean()*100)))\n",
        "\n",
        "print(\"\")\n",
        "print(55*\"=\")\n",
        "print(\"\")\n",
        "\n",
        "print('\\033[1;32mLightGBM Finalizado!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JiOElKZC9Fc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FFA500'> ETAPA 4: Comparando os algoritmos</font>"
      ],
      "metadata": {
        "id": "9ZSEb_AopRXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown > ### Rode a célula para fazer um comparativo entre os algoritmos em relação a acurácia.\n",
        "# Importando bibliotecas\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Atribuindo nomes para resultados\n",
        "Naive_Bayes = (sum(resultado_nbayes) / len(resultado_nbayes)) * 100\n",
        "S_V_M = (sum(resultado_svm) / len(resultado_svm)) * 100\n",
        "Reg_Logistica = (sum(resultado_rl) / len(resultado_rl)) * 100\n",
        "K_N_N = (sum(resultado_knn) / len(resultado_knn)) * 100\n",
        "Arv_Decisao = (sum(resultado_ad) / len(resultado_ad)) * 100\n",
        "R_Forest = (sum(resultado_rf) / len(resultado_rf)) * 100\n",
        "XG_BOOST = (sum(resultado_xgboost) / len(resultado_xgboost)) * 100\n",
        "Light_GBM = (sum(resultado_lgbm) / len(resultado_lgbm)) * 100\n",
        "\n",
        "# Criando lista com acurácias\n",
        "acuracia = [Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST, Light_GBM]\n",
        "maior_acuracia = max(acuracia)\n",
        "\n",
        "# Definindo nomes e cores\n",
        "nome_algoritmos = ['Naive_Bayes', 'S_V_M', 'Reg_Logistica', 'K_N_N', 'Arv_Decisao', 'R_Forest', 'XG_BOOST', 'Light_GBM']\n",
        "\n",
        "#cores = ['red' if acuracia[i] == maior_acuracia else 'blue' for i in range(len(acuracia))]\n",
        "cores = ['blue'] * len(acuracia)\n",
        "indice_maior_acuracia = acuracia.index(maior_acuracia)\n",
        "cores[indice_maior_acuracia] = 'red'\n",
        "\n",
        "\n",
        "\n",
        "# Criando gráfico:\n",
        "data = [go.Bar(x=nome_algoritmos, y=acuracia, marker=dict(color=cores))]\n",
        "\n",
        "# Configurando layout:\n",
        "layout = go.Layout(title='Comparação de acurácia de algoritmos de machine learning',\n",
        "                   xaxis=dict(title='Algoritmos'),\n",
        "                   yaxis=dict(title='Acurácia'))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\n",
        "#Naive_Bayes ,S_V_M, Reg_Logistica, K_N_N, Arv_Decisao, R_Forest, XG_BOOST e Light_GBM\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Og88Gqmomo-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}